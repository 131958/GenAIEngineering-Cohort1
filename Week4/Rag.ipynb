{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Pre-read for RAG Module Sessions 1 & 2: Building the Retrieval Foundation**\n",
    "\n",
    "This document provides a high-level overview of the first two sessions of the Retrieval-Augmented Generation (RAG) module, covering necessary installations, topics, and key learning objectives. We will focus on building the essential data preparation and retrieval components of a RAG system, with hands-on work centered around using the **Qdrant vector database** in its **local, in-memory configuration** via the `qdrant-client` library.\n",
    "\n",
    "### **Installation Prerequisites**\n",
    "\n",
    "To follow along with the practical exercises, you will need Python (3.8+ recommended) and the following libraries installed. We highly recommend using a virtual environment.\n",
    "\n",
    "Run the following command in your terminal:\n",
    "\n",
    "```shell\n",
    "    pip install langchain-text-splitters langchain-community langchain-huggingface langchain-qdrant sentence-transformers qdrant-client numpy scikit-learn rank_bm25\n",
    "```\n",
    "\n",
    "This command installs libraries for:\n",
    "\n",
    "* Text splitting (`langchain-text-splitters`).  \n",
    "* LangChain integrations for embeddings and vector stores (`langchain-community`, `langchain-huggingface`, `langchain-qdrant`).  \n",
    "* Generating vector embeddings (`sentence-transformers`).  \n",
    "* Interacting with Qdrant locally (`qdrant-client`).  \n",
    "* Numerical operations (`numpy`).  \n",
    "* Keyword search concepts (`scikit-learn` for TF-IDF, `rank_bm25` for BM25).\n",
    "\n",
    "**Note on Qdrant:** For these sessions, we will use the `qdrant-client` library to run Qdrant entirely in your local process memory (`location=\":memory:\"`). This requires **no separate Qdrant server installation or Docker setup**.\n",
    "\n",
    "### **Session 1: Foundations \\- Introduction to RAG and Document Preparation**\n",
    "\n",
    "**Session Goal:** Introduce the core concepts of RAG, explain why it's necessary, outline its workflow, and delve into preparing your data by chunking documents. We will also introduce the basics of keyword search and the fundamental idea of vectorization for semantic understanding.\n",
    "\n",
    "**Topics You Will Learn:**\n",
    "\n",
    "* **What is RAG and Why Use It?** Understand RAG as an architectural pattern to enhance LLMs by giving them access to external knowledge. Learn how RAG helps overcome LLM limitations like static knowledge, hallucination, and lack of access to private data. Explore various use cases.  \n",
    "* **Core RAG Architecture & Workflow:** Identify the main components: External Knowledge Source (Vector Database), Retriever, and Generator (LLM). Understand the Ingestion (data preparation, indexing) and Inference (query processing, retrieval, generation) stages.  \n",
    "* **Document Preparation: Chunking:** Learn why large documents must be split into smaller \"chunks\" due to LLM context window limitations. Understand that chunking strategy impacts retrieval quality.  \n",
    "* **Chunking Strategies:** Cover practical methods using LangChain:  \n",
    "  * **Fixed-Size Chunking:** Splitting by a fixed character count, with optional overlap.  \n",
    "  * **Recursive Character Text Splitting:** Splitting using a list of separators to preserve semantic units.  \n",
    "  * *(Other strategies like Semantic or Document-Based chunking will be mentioned conceptually)*.  \n",
    "* **Keyword Search Fundamentals:** Basic concepts like TF-IDF and BM25 will be introduced as traditional methods relying on exact word matching. Contrast this with semantic understanding.  \n",
    "* **Introduction to Vectorization:** Learn how text is converted into numerical vectors (embeddings) that capture meaning. Understand that texts with similar meanings are close in vector space. Introduction to **Transformer models** and **Sentence Transformers** like `all-MiniLM-L6-v2` for creating these embeddings.\n",
    "\n",
    "**Key Takeaways:**\n",
    "\n",
    "After Session 1, you should be able to:\n",
    "\n",
    "* Explain the purpose and workflow of a RAG system.  \n",
    "* Understand the need for and challenges of document chunking.  \n",
    "* **Implement fixed-size and recursive text splitting using LangChain**.  \n",
    "* Explain the difference between keyword search and semantic search.  \n",
    "* Understand the concept of vector embeddings and how they represent text meaning numerically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installing Prereqs\n",
    "!pip install -qq langchain-text-splitters langchain-community langchain-huggingface langchain-qdrant sentence-transformers qdrant-client numpy scikit-learn rank_bm25\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pre-req steps to use the Gemini API key with Python:\n",
    "\n",
    "1.  **Get API Key:** Go to [aistudio.google.com](https://aistudio.google.com/), sign in, and create/copy your API key (secure it immediately).\n",
    "2.  **Install Library:** In your terminal, run `pip install -q -U google-generativeai`.\n",
    "3.  **Set API Key Securely:**\n",
    "    * **Recommended:** Set it as an environment variable (e.g., `export GOOGLE_API_KEY=\"YOUR_KEY\"` in terminal/shell config).\n",
    "    * **Colab:** Use Colab Secrets to store `GOOGLE_API_KEY`.\n",
    "4.  **Configure in Python:** In your script, retrieve the key (e.g., `os.getenv('GOOGLE_API_KEY')` or `userdata.get('GOOGLE_API_KEY')`) and then use `genai.configure(api_key=YOUR_KEY)`.\n",
    "\n",
    "[Gemini API Key](https://aistudio.google.com/u/1/apikey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "from dotenv import load_dotenv  # For loading API key from a .env file\n",
    "import os\n",
    "load_dotenv()\n",
    "\n",
    "api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "genai.configure(api_key=api_key)\n",
    "\n",
    "model_name = 'gemini-2.0-flash'\n",
    "\n",
    "model = genai.GenerativeModel(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **What is RAG?**\n",
    "\n",
    "RAG is an AI framework that enhances the capabilities of LLMs by enabling them to access, retrieve, and incorporate external, up-to-date, and authoritative information into their responses. It combines the strengths of two distinct paradigms:\n",
    "\n",
    "1. **Retrieval:** The ability to efficiently search and retrieve relevant information from a vast corpus of documents.  \n",
    "2. **Generation:** The LLM's ability to generate coherent and contextually relevant text.\n",
    "\n",
    "In essence, RAG acts as a bridge, allowing LLMs to look up information in a knowledge base *before* formulating a response, much like a human would consult a textbook or database to answer a complex question.\n",
    "\n",
    "### **Why is RAG Needed?**\n",
    "\n",
    "RAG addresses several critical limitations of standalone LLMs:\n",
    "\n",
    "1. **Mitigating Hallucinations:** One of the most significant challenges with LLMs is their tendency to invent information, especially when they don't have a confident answer. By grounding their responses in retrieved facts, RAG significantly reduces the likelihood of hallucinations, leading to more reliable and trustworthy outputs.  \n",
    "2. **Access to Up-to-Date Information:** LLMs have a knowledge cutoff date, meaning they cannot access information beyond their last training update. RAG allows them to query continually updated databases, ensuring their responses are current and accurate, vital for dynamic fields like news, finance, or scientific research.  \n",
    "3. **Domain-Specific Knowledge:** Pre-trained LLMs are generalists. They lack specific knowledge about a particular company's internal documents, proprietary data, or niche industry information. RAG enables LLMs to tap into these private, domain-specific knowledge bases, making them useful for enterprise-level applications.  \n",
    "4. **Transparency and Explainability:** When using RAG, the generated answer can often be directly linked back to the source documents from which the information was retrieved. This provides a degree of explainability and allows users to verify the claims, building trust in the AI system.  \n",
    "5. **Reduced Training Costs:** Instead of constantly re-training or fine-tuning large models on new data (which is incredibly expensive and time-consuming), RAG offers a more agile way to update an LLM's knowledge by simply updating the external knowledge base.\n",
    "\n",
    "### **How RAG Works (The Process)**\n",
    "\n",
    "The RAG process typically involves three main steps:\n",
    "\n",
    "1. **Retrieval:** When a user poses a query (Q), the system first searches a vast external knowledge base (D) (e.g., a vector database containing embeddings of documents, or a conventional search index). The goal is to retrieve the most relevant passages, documents, or snippets (R) related to the query. This step often uses techniques like semantic search, keyword search (BM25), or hybrid approaches.\n",
    "\n",
    "    R=Retrieve(Q,D)  \n",
    "2. **Augmentation:** The retrieved information (R) is then concatenated or integrated with the original user query (Q) to form an augmented prompt (). This new, enriched prompt provides the LLM with the necessary context and factual grounding.\n",
    "\n",
    "    Paug​=Augment(Q,R)  \n",
    "3. **Generation:** Finally, the augmented prompt (Paug​) is fed into the LLM. The LLM then generates a coherent and accurate answer (A) based on its inherent language understanding capabilities and the specific information provided in the augmented prompt.\n",
    "\n",
    "    A=Generate(Paug​,LLM)\n",
    "\n",
    "In essence, RAG transforms an LLM from a black box of pre-trained knowledge into a dynamic, fact-checking, and context-aware reasoning engine, making it a powerful tool for building more reliable and sophisticated AI applications.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay! Unfortunately, I don't have direct access to your company's attendance data. To figure out which day has the lowest employee attendance, you'll need to look at your internal records.\n",
      "\n",
      "Here's how you can find that information:\n",
      "\n",
      "1.  **Check your HR or Timekeeping System:** Your HR department or the system you use for tracking employee hours (like time clocks, attendance software, or even spreadsheets) will be the best source of this data.\n",
      "2.  **Analyze Historical Data:** Look at attendance records over a significant period (e.g., the past year) to account for seasonal variations, holidays, and other factors.\n",
      "3.  **Calculate Average Attendance:** For each day of the week, calculate the average number of employees present (or the percentage of employees present).\n",
      "4.  **Compare Averages:** Compare the averages you calculated. The day with the lowest average attendance is the day you're looking for.\n",
      "\n",
      "Once you do that, you should be able to get a good answer!\n",
      "\n",
      "I hope this helps! If you need help with something else, let me know!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Without any context\n",
    "\n",
    "prompt = '''\n",
    "Given the user query, answer the user to the best of your ability.\n",
    "Enusre you are polite and helpful.\n",
    "If you do not know the answer, say \"I don't know\" and offer to help with something else.\n",
    "\n",
    "User Query: {user_query}\n",
    "'''\n",
    "\n",
    "user_query = 'I need to know which day of the week is the lowest employee attendance.'\n",
    "\n",
    "response = model.generate_content(prompt.format(user_query=user_query))\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, I can help you determine which day of the week has the lowest employee attendance based on the data you provided.\n",
      "\n",
      "First, I need to sum the attendance for each day:\n",
      "\n",
      "*   **Monday:** 1 + 0 + 0 + 1 + 1 + 0 + 1 + 1 + 0 + 1 = 6\n",
      "*   **Tuesday:** 0 + 0 + 1 + 1 + 1 + 0 + 1 + 0 + 0 + 1 = 5\n",
      "*   **Wednesday:** 0 + 1 + 0 + 0 + 1 + 1 + 0 + 1 + 0 + 1 = 5\n",
      "*   **Thursday:** 1 + 1 + 1 + 1 + 1 + 1 + 0 + 0 + 0 + 0 = 6\n",
      "*   **Friday:** 0 + 0 + 1 + 1 + 1 + 1 + 0 + 1 + 1 + 1 = 7\n",
      "\n",
      "Based on these sums:\n",
      "\n",
      "*   Tuesday and Wednesday have the lowest attendance with 5 employees present.\n",
      "\n",
      "Therefore, the days with the lowest employee attendance are **Tuesday and Wednesday**.\n"
     ]
    }
   ],
   "source": [
    "# With Context\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "attendance = np.random.randint(0, 2, size=(10, 5))\n",
    "\n",
    "attendance = pd.DataFrame(\n",
    "    attendance, columns=['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday'])\n",
    "attendance.index.name = 'Employee ID'\n",
    "\n",
    "context = attendance.to_markdown()\n",
    "\n",
    "\n",
    "prompt = '''\n",
    "Given the user query, answer the user to the best of your ability.\n",
    "Enusre you are polite and helpful.\n",
    "If you do not know the answer, say \"I don't know\" and offer to help with something else.\n",
    "\n",
    "User Query: {user_query}\n",
    "\n",
    "Context:\n",
    "\n",
    "{context}\n",
    "'''\n",
    "\n",
    "response = model.generate_content(\n",
    "    prompt.format(\n",
    "        user_query=user_query,\n",
    "        context=context,\n",
    "    )\n",
    ")\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Predicting Freeway Congestion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Supervised Learning of Query Term Relevant Pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Robotic Arm Control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Network Intrusion Detection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Multi-Website Name Coreference Resolution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2587</th>\n",
       "      <td>Sentimental Analysis with Amazon Review Data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2588</th>\n",
       "      <td>Bird Classification and Feature Recognition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2589</th>\n",
       "      <td>Human or Robot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2590</th>\n",
       "      <td>Predicting NBA shots</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2591</th>\n",
       "      <td>Poverty Prediction by Selected Remote Sensing ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2592 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text\n",
       "0                         Predicting Freeway Congestion\n",
       "1     Supervised Learning of Query Term Relevant Pro...\n",
       "2                                   Robotic Arm Control\n",
       "3                           Network Intrusion Detection\n",
       "4             Multi-Website Name Coreference Resolution\n",
       "...                                                 ...\n",
       "2587       Sentimental Analysis with Amazon Review Data\n",
       "2588        Bird Classification and Feature Recognition\n",
       "2589                                     Human or Robot\n",
       "2590                               Predicting NBA shots\n",
       "2591  Poverty Prediction by Selected Remote Sensing ...\n",
       "\n",
       "[2592 rows x 1 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading Sample Dataset\n",
    "# https://raw.githubusercontent.com/paraschopra/generating-text-small-corpus/refs/heads/master/all_ml_ideas.csv\n",
    "\n",
    "corpus = pd.read_csv(\n",
    "    'all_ml_ideas.csv',\n",
    "    sep='------',\n",
    "    engine='python',\n",
    "    header=None,\n",
    "    names=['text']\n",
    ")\n",
    "corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Keyword Search\n",
    "\n",
    "Keyword search represents the most fundamental and intuitive form of information retrieval, forming the backbone of search engines for decades. At its core, keyword search operates on a simple premise: it matches the specific words (keywords) entered by a user in a query against the words present in a collection of documents. It's often the first interaction point for users seeking information, relying on direct lexical matches rather than deeper semantic understanding.\n",
    "\n",
    "### **The Core Principle**\n",
    "\n",
    "When a user inputs a query, a keyword search engine takes these terms and looks for their occurrences within its indexed documents. The primary goal is to identify documents that contain one or more of the specified keywords. For instance, if a user searches for \"best Italian restaurant,\" the system would attempt to find documents containing \"best,\" \"Italian,\" and \"restaurant.\"\n",
    "\n",
    "To facilitate rapid searching, keyword search engines typically rely on an **inverted index**. An inverted index is essentially a data structure that maps terms to the documents in which they appear. It looks something like this:\n",
    "\n",
    "* \"restaurant\" \\[Document 1, Document 5, Document 12\\]  \n",
    "* \"Italian\" → \\[Document 1, Document 8, Document 12\\]  \n",
    "* \"best\" → \\[Document 5, Document 12, Document 20\\]\n",
    "\n",
    "When a query comes in, the engine quickly consults this index to retrieve a list of documents containing the query terms.\n",
    "\n",
    "### **Basic Ranking and Relevance**\n",
    "\n",
    "Once a set of matching documents is identified, they need to be ranked by relevance. In its simplest form, a keyword search might rank documents based on:\n",
    "\n",
    "1. Number of Matching Keywords: Documents containing more of the query terms are considered more relevant. For example, a document containing all three terms (\"best,\" \"Italian,\" \"restaurant\") would be ranked higher than one containing only \"Italian\" and \"restaurant.\" A very simple conceptual score could be represented as:  \n",
    "   Let Q=q1​,q2​,…,qm​ be the set of keywords in the query, and D be a document.  \n",
    "2. Score(D,Q)=i=1∑m​I(qi​∈D)  \n",
    "3. where I(qi​∈D) is an indicator function that equals 1 if term qi​ is present in document D, and 0 otherwise.  \n",
    "4. **Keyword Proximity:** Documents where the keywords appear closer together are often ranked higher, as this might indicate a more coherent discussion of the topic.  \n",
    "5. **Term Position:** Keywords appearing in important fields like the document title, headings, or metadata might be given more weight than those in the body text.  \n",
    "6. **Boolean Logic:** Users can often refine queries using Boolean operators like AND (all terms must be present), OR (at least one term must be present), and NOT (a term must not be present).\n",
    "\n",
    "### **Advantages of Keyword Search**\n",
    "\n",
    "* **Simplicity:** It's easy for users to understand and for developers to implement a basic version.  \n",
    "* **Speed:** With well-optimized inverted indexes, keyword searches can be incredibly fast, even across vast document collections.  \n",
    "* **Effectiveness for Precise Queries:** When a user knows the exact terms they are looking for, keyword search can be highly effective in retrieving relevant results.\n",
    "\n",
    "### **Limitations of Keyword Search**\n",
    "\n",
    "Despite its widespread use, keyword search suffers from significant limitations:\n",
    "\n",
    "* **Lack of Semantic Understanding:** This is its most prominent drawback. Keyword search cannot grasp the underlying meaning or intent behind words. It treats \"car\" and \"automobile\" as distinct terms, failing to recognize them as synonyms. It also struggles with polysemy (words with multiple meanings, like \"bank\").  \n",
    "* **Ignores Word Order and Context:** Unless explicitly using an exact phrase search (e.g., \"machine learning\" in quotes), keyword search views text as a \"bag of words.\" It cannot distinguish between \"man bites dog\" and \"dog bites man.\"  \n",
    "* **Recall and Precision Issues:** It can suffer from low **recall** (failing to retrieve all relevant documents if they use different vocabulary) and low **precision** (retrieving irrelevant documents if keywords are too broad or common).  \n",
    "* **Spelling Sensitivity:** It is highly sensitive to typos and misspellings; a single incorrect letter can lead to zero results.\n",
    "\n",
    "In conclusion, keyword search remains a fundamental component of most search systems due to its speed and simplicity. However, its inherent limitations regarding semantic understanding and contextual awareness have driven the development of more sophisticated techniques like TF-IDF, BM25, and ultimately, neural network-based semantic search models that aim to bridge the gap between keywords and true meaning.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('What is the best way to learn machine learning?',\n",
       " ['best', 'way', 'learn', 'machine', 'learning'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')\n",
    "\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Tokenize the text\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    # Remove stopwords\n",
    "    tokens = [\n",
    "        word for word in tokens if word not in stopwords.words('english')]\n",
    "    # Remove special characters\n",
    "    tokens = [re.sub(r'[^a-zA-Z0-9]', '', word) for word in tokens]\n",
    "    # Remove empty strings\n",
    "    tokens = [word for word in tokens if word != '']\n",
    "    return tokens\n",
    "\n",
    "\n",
    "search_query = 'What is the best way to learn machine learning?'\n",
    "\n",
    "preprocessed_query = preprocess_text(search_query)\n",
    "\n",
    "search_query, preprocessed_query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Bag-of-Words (BoW) model\n",
    "\n",
    "The Bag-of-Words (BoW) model is a foundational and historically significant technique in natural language processing (NLP) and information retrieval. At its core, BoW simplifies text representation by treating a document or query as an unordered collection of its words, essentially like words thrown into a \"bag.\" The key characteristic is that it disregards grammar, syntax, and even the order of words, focusing solely on the presence and frequency of individual words within the text.\n",
    "\n",
    "### **How Bag-of-Words Works for Search**\n",
    "\n",
    "For a search engine to utilize a BoW model, it first processes a large collection of documents to build a comprehensive vocabulary – a unique list of all words found across the entire corpus. Each word in this vocabulary becomes a feature or dimension in a vector space.\n",
    "\n",
    "When a document is processed, it's converted into a vector where each component corresponds to a word in the vocabulary, and its value typically represents the frequency of that word within the document. For example, if the vocabulary contains \"cat,\" \"dog,\" \"chase,\" and \"tree,\" and a document is \"The cat chases the dog,\" its BoW representation might be {\"cat\": 1, \"dog\": 1, \"chase\": 1} (ignoring common words like \"the\").\n",
    "\n",
    "When a user submits a search query, that query is also transformed into a similar BoW vector. The search engine then calculates the similarity between the query's vector and the vectors of all documents in its index. Common similarity measures include:\n",
    "\n",
    "* **Dot Product:** A simple count of shared words.  \n",
    "* **Cosine Similarity:** Measures the cosine of the angle between two vectors, indicating how similar their directions are. This is often preferred as it's normalized by document length, preventing longer documents from being unfairly favored just because they contain more words.\n",
    "\n",
    "Documents are then ranked based on their similarity scores to the query, with higher scores indicating greater relevance.\n",
    "\n",
    "### **Enhancements to the Basic BoW Model**\n",
    "\n",
    "While the core BoW is straightforward, several enhancements improve its effectiveness:\n",
    "\n",
    "* **Stop Words Removal:** Common words like \"a,\" \"the,\" \"is,\" \"and\" are often removed before creating the BoW. These words are frequent but carry little semantic meaning for distinguishing documents. Removing them reduces noise and improves efficiency.  \n",
    "* **Stemming and Lemmatization:** To account for variations of words (e.g., \"run,\" \"running,\" \"ran\"), stemming (reducing words to their root, like \"run\") or lemmatization (reducing words to their dictionary form, like \"am,\" \"is,\" \"are\" to \"be\") is applied. This ensures that different grammatical forms of the same word are treated as identical, improving matching accuracy.  \n",
    "* **TF-IDF (Term Frequency-Inverse Document Frequency):** This is a widely used weighting scheme that goes beyond simple word counts.  \n",
    "  * **Term Frequency (TF):** Measures how frequently a word appears in a document.  \n",
    "  * Inverse Document Frequency (IDF): Measures how rare a word is across the entire document collection. Words that are rare but appear in a specific document are considered more important.  \n",
    "    By multiplying TF and IDF, the BoW model gives more weight to words that are both frequent in a specific document and rare across the entire corpus, thus improving the relevance ranking.\n",
    "\n",
    "### **Advantages and Limitations**\n",
    "\n",
    "The Bag-of-Words model offers several advantages:\n",
    "\n",
    "* **Simplicity and Interpretability:** It's conceptually easy to understand and implement.  \n",
    "* **Computational Efficiency:** Building and comparing BoW representations is computationally less demanding compared to more advanced methods.  \n",
    "* **Effectiveness:** Despite its simplicity, it performs reasonably well for many fundamental text classification and retrieval tasks, serving as a strong baseline.\n",
    "\n",
    "However, BoW also has significant limitations:\n",
    "\n",
    "* **Loss of Semantic Meaning and Word Order:** This is its most critical drawback. BoW completely ignores the context, grammar, and order of words. For instance, \"The dog bit the man\" and \"The man bit the dog\" would have identical BoW representations, even though their meanings are vastly different. It cannot capture phrases or idiomatic expressions.  \n",
    "* **Synonymy and Polysemy:** It struggles with synonyms (e.g., \"car\" and \"automobile\" are treated as distinct words) and polysemy (words with multiple meanings, like \"bank\" – a river bank vs. a financial institution – are treated as the same word).  \n",
    "* **High Dimensionality and Sparsity:** For large text corpora, the vocabulary can become enormous, leading to high-dimensional vectors that are mostly empty (sparse), making computations less efficient and potentially impacting accuracy.\n",
    "\n",
    "In conclusion, while the Bag-of-Words model remains a foundational concept and is surprisingly effective for its simplicity, its inherent limitation of ignoring word order and deeper semantic relationships has paved the way for more sophisticated NLP techniques like word embeddings (Word2Vec, GloVe) and, more recently, transformer-based models (like BERT, GPT, and Gemini), which are designed to capture contextual and semantic nuances of language.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['what', 'is', 'the', 'best', 'way', 'to', 'learn', 'machine', 'learning']\n",
      "|      | text                                                                                             |   score |\n",
      "|-----:|:-------------------------------------------------------------------------------------------------|--------:|\n",
      "|  807 | An application of machine learning to the board game pentago                                     |       5 |\n",
      "| 2479 | A machine learning based stock trading framework using technical and economic analysis           |       5 |\n",
      "| 2124 | Applying machine learning to the board game Pylos                                                |       5 |\n",
      "|  693 | Early defect identification of semiconductor processes using machine learning                    |       4 |\n",
      "| 2252 | Uncertainty quantification and sensitivity analysis of reservoir forecasts with machine learning |       4 |\n",
      "| 1851 | Advanced machine learning techniques for thyroid cancer diagnosis                                |       4 |\n",
      "| 1391 | CarveML an application of machine learning to file fragment classification                       |       4 |\n",
      "|  811 | Applying machine learning algorithms to oil reservoir production optimization                    |       4 |\n",
      "|  144 | Exploring machine learning techniques for recommending advertising keywords                      |       4 |\n",
      "| 2480 | Supervised learning methods for biometric authentication on mobile devices                       |       4 |\n"
     ]
    }
   ],
   "source": [
    "# Brute Force Search with Score based ranking\n",
    "\n",
    "import re\n",
    "# regex replace only to keep alphanumeric characters\n",
    "# and remove special characters\n",
    "pattern = r'[^a-zA-Z0-9\\s]'\n",
    "\n",
    "search_tokens = re.sub(pattern, '', search_query).lower().split()\n",
    "\n",
    "print(search_tokens)\n",
    "\n",
    "\n",
    "def score(text, search_tokens):\n",
    "    score = 0\n",
    "    for token in search_tokens:\n",
    "        if token in text:\n",
    "            score += 1\n",
    "    return score\n",
    "\n",
    "\n",
    "def brute_search(corpus, search_tokens):\n",
    "    corpus = corpus.copy()\n",
    "    corpus['score'] = corpus['text'].apply(lambda x: score(x, search_tokens))\n",
    "    return corpus.sort_values(by='score', ascending=False)\n",
    "\n",
    "\n",
    "print(brute_search(corpus, search_tokens).head(10).to_markdown())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF Vectorization and Search\n",
    "\n",
    "In the realm of information retrieval and natural language processing, simply counting words (as in the basic Bag-of-Words model) often falls short in determining the true relevance of a document to a search query. This is where TF-IDF, short for Term Frequency-Inverse Document Frequency, emerges as a powerful and widely used statistical measure. TF-IDF provides a numerical statistic that reflects how important a word is to a document in a collection or corpus.\n",
    "\n",
    "### **Breaking Down TF-IDF**\n",
    "\n",
    "The TF-IDF score for a word in a document is a product of two components:\n",
    "\n",
    "1. **Term Frequency (TF):** This measures how frequently a term (word) appears within a specific document. The idea is straightforward: if a word appears many times in a document, it's likely to be important to that document's content. However, simply using raw counts can be misleading, as longer documents will naturally have higher term frequencies for most words. To mitigate this, TF is often normalized, for example, by dividing the raw count by the total number of terms in the document. TF(t,d)=Total number of terms in document dNumber of times term t appears in document d​  \n",
    "2. **Inverse Document Frequency (IDF):** While TF highlights words frequent within a document, it doesn't account for the overall importance of the word across the entire collection of documents. Words like \"the,\" \"a,\" and \"is\" appear frequently in almost all documents but carry little unique meaning or discriminative power. IDF addresses this by assigning a higher weight to terms that are rare across the entire corpus and a lower weight to common terms. IDF(t,D)=log(Number of documents d containing term tTotal number of documents N​) The logarithm helps to scale the values. A higher IDF indicates that the term is rare and therefore more significant.\n",
    "\n",
    "### **The TF-IDF Score and Vectorization**\n",
    "\n",
    "The TF-IDF score for a term in a document is then calculated by multiplying its TF and IDF values: TFIDF(t,d,D)=TF(t,d)×IDF(t,D)\n",
    "\n",
    "This combined score assigns a high value to terms that appear frequently in a particular document but rarely in the overall corpus. Conversely, terms that are common across many documents (like stop words) or very rare in a single document will have low TF-IDF scores.\n",
    "\n",
    "**TF-IDF Vectorization** involves representing each document in a collection as a vector in a high-dimensional space. Each dimension of this vector corresponds to a unique term in the vocabulary of the entire corpus. The value for each dimension in a document's vector is the TF-IDF score of the corresponding term within that document. This process transforms unstructured text into a structured numerical format that machine learning algorithms can easily process.\n",
    "\n",
    "### **TF-IDF for Search**\n",
    "\n",
    "When a user submits a search query, the same TF-IDF vectorization process is applied to the query itself. The query is treated as a short document, and its terms are assigned TF-IDF weights based on their frequency in the query and their inverse document frequency across the entire document collection.\n",
    "\n",
    "Once both the query and all documents in the collection are represented as TF-IDF vectors, search becomes a problem of **vector space model similarity**. The search engine calculates the similarity between the query vector and each document vector. The most common similarity metric used for this is **Cosine Similarity**, which measures the cosine of the angle between two vectors. A cosine similarity closer to 1 indicates higher similarity (vectors pointing in the same direction), meaning the document is highly relevant to the query.\n",
    "\n",
    "The documents are then ranked in descending order of their cosine similarity scores, presenting the most relevant results to the user first.\n",
    "\n",
    "### **Advantages and Limitations**\n",
    "\n",
    "**Advantages of TF-IDF:**\n",
    "\n",
    "* **Improved Relevance:** By giving more weight to rare and important terms, TF-IDF often produces more relevant search results compared to simple Bag-of-Words counts.  \n",
    "* **Handles Common Words:** The IDF component effectively down-weights common, less informative words, preventing them from dominating the similarity scores.  \n",
    "* **Simplicity and Scalability:** It's relatively simple to compute and scales well to large document collections.\n",
    "\n",
    "**Limitations of TF-IDF:**\n",
    "\n",
    "* **Semantic Blindness:** Like the basic BoW model, TF-IDF still operates at the word level and completely ignores the semantic relationships between words (e.g., \"car\" and \"automobile\" are treated as distinct terms). It cannot understand context or nuances of language.  \n",
    "* **Word Order Ignorance:** It does not consider the order of words, meaning phrases and the grammatical structure of sentences are lost.  \n",
    "* **Sparse Vectors:** For very large vocabularies, TF-IDF vectors can be extremely high-dimensional and sparse (mostly zeros), which can be computationally inefficient for some operations.\n",
    "\n",
    "Despite its limitations, TF-IDF remains a cornerstone in information retrieval, often used as a baseline or as a feature engineering technique in more complex systems. Its effectiveness and simplicity make it a valuable tool for understanding and processing text data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|      | text                                                               |   similarity |\n",
      "|-----:|:-------------------------------------------------------------------|-------------:|\n",
      "|  699 | Finding the Best Photo                                             |     0.358477 |\n",
      "| 1550 | What Can You Learn From Accelerometer Data                         |     0.319214 |\n",
      "|  675 | Can a machine learn to teach?                                      |     0.30413  |\n",
      "| 1764 | What can we learn from a movie's color?                            |     0.298678 |\n",
      "| 1983 | Finding Your Way, Courtesy of Machine Learning                     |     0.285296 |\n",
      "| 1520 | A novel way to Soccer Match Prediction                             |     0.260768 |\n",
      "| 1991 | Learn To Rate Fine Food                                            |     0.233312 |\n",
      "| 1882 | The Price is Right? Estimating Medical Costs with Machine Learning |     0.2305   |\n",
      "|   26 | This Sentence is Not a Question, or Is It?                         |     0.22556  |\n",
      "|  522 | 4-Way-Stop Wait-Time Prediction                                    |     0.214432 |\n"
     ]
    }
   ],
   "source": [
    "# Building a TF-IDF Vectorizer based search engine\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform(corpus['text'])\n",
    "\n",
    "\n",
    "def search_tfidf(corpus, search_query):\n",
    "    corpus = corpus.copy()\n",
    "    search_query_vector = vectorizer.transform([search_query])\n",
    "    similarity = cosine_similarity(search_query_vector, tfidf_matrix).flatten()\n",
    "    corpus['similarity'] = similarity\n",
    "    return corpus.sort_values(by='similarity', ascending=False)\n",
    "\n",
    "\n",
    "print(search_tfidf(corpus, search_query).head(10).to_markdown())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While TF-IDF (Term Frequency-Inverse Document Frequency) has been a cornerstone of information retrieval for decades, the Okapi BM25 (Best Match 25\\) ranking function emerged as a more sophisticated and often more effective approach to calculating document relevance for a given search query. BM25 is a probabilistic retrieval model that builds upon the TF-IDF concept, but with significant improvements, particularly in how it handles term frequency saturation and document length normalization. It's widely used in modern search engines due to its empirical effectiveness.\n",
    "\n",
    "### **How BM25 Works**\n",
    "\n",
    "BM25 calculates a relevance score for each document with respect to a search query. This score is a sum of the scores for each term in the query. For a query containing terms q1​,…,qn​, the BM25 score for a document D is typically calculated as:\n",
    "\n",
    "$$\n",
    "Score(D, Q) = \\sum_{i=1}^{n} IDF(q_i) \\cdot \\frac{f(q_i, D) \\cdot (k_1 + 1)}{f(q_i, D) + k_1 \\cdot \\left(1 - b + b \\cdot \\frac{|D|}{avgdl}\\right)}\n",
    "$$\n",
    "Let's break down the components:\n",
    "\n",
    "1. **IDF (Inverse Document Frequency):** Similar to TF-IDF, BM25 uses IDF to weigh terms. Rare terms across the corpus contribute more to the total score than common terms. The formula for IDF in BM25 often uses a slightly different variant to the standard log function in TF-IDF, sometimes including smoothing terms to avoid division by zero for terms appearing in no documents. IDF(qi​) is the Inverse Document Frequency of term qi​.  \n",
    "2. **Term Frequency (**f(qi​,D)**):** This represents how many times term qi​ appears in document D. Unlike raw TF, BM25 incorporates parameters k1​ and b to prevent term frequency from saturating.  \n",
    "   * **Saturation:** In simple TF, a word appearing 100 times in a document contributes 100 times as much as a word appearing once. BM25 acknowledges that beyond a certain point, additional occurrences of a term provide diminishing returns to relevance. The k1​ parameter controls this saturation point. Higher values of k1​ lead to less saturation.  \n",
    "   * The term f(qi​,D)+k1​f(qi​,D)⋅(k1​+1)​ is the core of how BM25 handles term frequency, allowing it to give more weight to more frequent terms up to a point, then the contribution levels off.  \n",
    "3. **Document Length Normalization (**∣D∣ **and** avgdl**):** This part of the formula addresses the issue of longer documents potentially having higher raw term frequencies simply because they are longer.  \n",
    "   * ∣D∣ is the length of the document D (e.g., in words).  \n",
    "   * avgdl is the average document length in the corpus.  \n",
    "   * The parameter b (often between 0 and 1\\) controls the degree of document length normalization.  \n",
    "     * If b=0, no length normalization is applied.  \n",
    "     * If b=1, full length normalization is applied. The term (1−b+b⋅avgdl∣D∣​) scales the denominator, effectively reducing the impact of term frequency in longer documents relative to shorter ones, especially if the term is not particularly frequent in the longer document compared to its overall length.\n",
    "\n",
    "### **BM25 for Search**\n",
    "\n",
    "When a query is submitted, each document's BM25 score is calculated based on the query terms. Documents are then ranked by their BM25 scores, from highest to lowest, to present the most relevant results. The parameters k1​ (typically between 1.2 and 2.0) and b (typically around 0.75) are tunable and often optimized based on the specific characteristics of the document corpus and search task.\n",
    "\n",
    "### **Advantages and Limitations**\n",
    "\n",
    "**Advantages of BM25:**\n",
    "\n",
    "* **Improved Relevance:** BM25 generally outperforms plain TF-IDF in most retrieval scenarios due to its refined handling of term frequency saturation and document length normalization.  \n",
    "* **Probabilistic Foundation:** Its roots in probabilistic models provide a more theoretically sound basis for relevance estimation compared to the heuristic nature of raw TF-IDF.  \n",
    "* **Robustness:** It is relatively robust and performs well across diverse datasets without extensive tuning.\n",
    "\n",
    "**Limitations of BM25:**\n",
    "\n",
    "* **Semantic Gap:** Like TF-IDF, BM25 is a keyword-matching algorithm. It still suffers from the \"semantic gap\" problem, meaning it doesn't understand synonyms (e.g., \"car\" and \"automobile\" are treated as distinct) or the deeper meaning and context of words.  \n",
    "* **Word Order Ignorance:** It treats the query and documents as a \"bag of words,\" ignoring the order of words and thus failing to capture phrases or idiomatic expressions.  \n",
    "* **Parameter Tuning:** While robust, optimal performance can sometimes require careful tuning of k1​ and b for specific corpora.  \n",
    "* **Outperformed by Modern Methods:** For complex search tasks requiring deep semantic understanding, BM25 is often surpassed by neural network-based models and dense retrieval methods (like those using word embeddings or transformer models) that capture contextual relationships.\n",
    "\n",
    "Despite the emergence of more advanced neural retrieval methods, BM25 remains a highly effective, computationally efficient, and widely used ranking function in many practical search systems, often serving as a strong baseline or even a crucial component in hybrid retrieval architectures.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /usr/local/google/home/vermavineet/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /usr/local/google/home/vermavineet/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|      | text                                           | tokens                                                |    score |\n",
      "|-----:|:-----------------------------------------------|:------------------------------------------------------|---------:|\n",
      "| 1983 | Finding Your Way, Courtesy of Machine Learning | ['finding', 'way', 'courtesy', 'machine', 'learning'] | 10.7682  |\n",
      "|  675 | Can a machine learn to teach?                  | ['machine', 'learn', 'teach']                         | 10.0588  |\n",
      "|  699 | Finding the Best Photo                         | ['finding', 'best', 'photo']                          |  9.37019 |\n",
      "| 1708 | Win Some, Learn Some                           | ['win', 'learn']                                      |  8.01062 |\n",
      "| 1359 | Can Machines Learn Genres                      | ['machines', 'learn', 'genres']                       |  7.18643 |\n",
      "|  885 | How well do people learn?                      | ['well', 'people', 'learn']                           |  7.18643 |\n",
      "| 1550 | What Can You Learn From Accelerometer Data     | ['learn', 'accelerometer', 'data']                    |  7.18643 |\n",
      "| 1520 | A novel way to Soccer Match Prediction         | ['novel', 'way', 'soccer', 'match', 'prediction']     |  6.88701 |\n",
      "| 1991 | Learn To Rate Fine Food                        | ['learn', 'rate', 'fine', 'food']                     |  6.51602 |\n",
      "| 1764 | What can we learn from a movie's color?        | ['learn', 'movie', 's', 'color']                      |  6.51602 |\n"
     ]
    }
   ],
   "source": [
    "# rank_bm25 based search engine\n",
    "from rank_bm25 import BM25Okapi\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Tokenize the text\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    # Remove stopwords\n",
    "    tokens = [\n",
    "        word for word in tokens if word not in stopwords.words('english')]\n",
    "    # Remove special characters\n",
    "    tokens = [re.sub(r'[^a-zA-Z0-9]', '', word) for word in tokens]\n",
    "    # Remove empty strings\n",
    "    tokens = [word for word in tokens if word != '']\n",
    "    return tokens\n",
    "\n",
    "\n",
    "corpus['tokens'] = corpus['text'].apply(preprocess_text)\n",
    "corpus['tokens'].head(10).to_markdown()\n",
    "# BM25\n",
    "bm25 = BM25Okapi(corpus['tokens'].tolist())\n",
    "\n",
    "\n",
    "def search_bm25(corpus, search_query):\n",
    "    corpus = corpus.copy()\n",
    "    search_query_tokens = preprocess_text(search_query)\n",
    "    scores = bm25.get_scores(search_query_tokens)\n",
    "    corpus['score'] = scores\n",
    "    return corpus.sort_values(by='score', ascending=False)\n",
    "\n",
    "\n",
    "print(search_bm25(corpus, search_query).head(10).to_markdown())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector Embeddings on text\n",
    "\n",
    "In the realm of natural language processing (NLP), computers don't inherently understand human language. Words, phrases, and documents are abstract concepts to a machine. **Vector embeddings** are a revolutionary technique that bridges this gap by converting textual data into dense numerical representations, or vectors, in a continuous vector space. These vectors capture the semantic meaning and contextual relationships of words and phrases, allowing machines to process and \"understand\" language in a way that was previously impossible with traditional methods like Bag-of-Words or TF-IDF.\n",
    "\n",
    "### **What are Vector Embeddings?**\n",
    "\n",
    "At its core, a vector embedding is an array of real numbers (e.g., `[0.1, -0.5, 0.8, 0.2, ...]`) that represents a piece of text. Each number in the array corresponds to a dimension in the vector space. The magic lies in how these numbers are assigned: words or phrases that are semantically similar tend to be located closer together in this high-dimensional space, while dissimilar terms are further apart. For instance, the vector for \"king\" might be close to \"queen\" and \"man,\" and the vector difference between \"king\" and \"man\" could be similar to the difference between \"queen\" and \"woman.\"\n",
    "\n",
    "### **Why are They Needed?**\n",
    "\n",
    "Traditional text representation methods like Bag-of-Words or TF-IDF suffer from significant limitations:\n",
    "\n",
    "* **Lack of Semantic Understanding:** They treat words as independent entities, ignoring synonyms, polysemy, and the underlying meaning. \"Car\" and \"automobile\" would be seen as entirely different terms.  \n",
    "* **High Dimensionality and Sparsity:** For large vocabularies, vectors can become extremely long and mostly filled with zeros, leading to inefficient computation and storage.  \n",
    "* **No Contextual Information:** They cannot capture the meaning of a word based on its surrounding words.\n",
    "\n",
    "Vector embeddings overcome these limitations by:\n",
    "\n",
    "* **Capturing Semantic Similarity:** They embed words with similar meanings close to each other in the vector space.  \n",
    "* **Capturing Relationships:** They can learn analogies and relationships between words.  \n",
    "* **Reduced Dimensionality:** They represent text in dense, lower-dimensional vectors compared to sparse, high-dimensional representations.\n",
    "\n",
    "### **How are Vector Embeddings Generated?**\n",
    "\n",
    "Vector embeddings are typically learned from vast amounts of text data using various machine learning techniques:\n",
    "\n",
    "1. **Context-Independent Embeddings (e.g., Word2Vec, GloVe):** These models learn a single, fixed embedding for each word, regardless of its context. They analyze the co-occurrence patterns of words in a large corpus. If words frequently appear together or in similar contexts, their embeddings will be closer.  \n",
    "2. **Contextual Embeddings (e.g., BERT, GPT, Gemini Embeddings):** More advanced models, particularly those based on the Transformer architecture, generate embeddings that are *context-dependent*. This means the embedding for a word like \"bank\" would be different if it's used in the context of a \"river bank\" versus a \"financial bank.\" These models process entire sentences or paragraphs to generate rich, context-aware representations for each word or even for the entire input.\n",
    "\n",
    "### **How are Vector Embeddings Used in Search?**\n",
    "\n",
    "Vector embeddings are crucial for **semantic search**, which goes beyond simple keyword matching:\n",
    "\n",
    "1. **Vectorizing Documents:** All documents in a corpus are transformed into their corresponding embedding vectors using a pre-trained embedding model. These vectors are then stored in a specialized database called a **vector database** (or vector index).  \n",
    "2. **Vectorizing Queries:** When a user submits a query, it is also converted into an embedding vector using the *same* embedding model.  \n",
    "3. **Similarity Search:** Instead of matching keywords, the search engine now performs a **similarity search** in the vector space. It finds document vectors that are \"closest\" to the query vector. The most common metric for measuring this similarity is **Cosine Similarity**: Let and B be two embedding vectors.\n",
    "\n",
    "$$\n",
    "\\text{Cosine Similarity}(A, B) = \\frac{A \\cdot B}{||A|| \\cdot ||B||} = \\frac{\\sum_{i=1}^{n} A_i B_i}{\\sqrt{\\sum_{i=1}^{n} A_i^2} \\sqrt{\\sum_{i=1}^{n} B_i^2}}\n",
    "$$\n",
    "\n",
    "A cosine similarity score close to 1 indicates high semantic similarity.\n",
    "\n",
    "Documents are then ranked based on their cosine similarity scores to the query vector. This allows the search engine to retrieve documents that might not contain the exact keywords but are semantically related to the query, significantly improving search relevance and recall.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>The King won ...</th>\n",
       "      <th>The Man won ...</th>\n",
       "      <th>The Queen won ...</th>\n",
       "      <th>The Woman won ...</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>The King won ...</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.830</td>\n",
       "      <td>0.866</td>\n",
       "      <td>0.712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The Man won ...</th>\n",
       "      <td>0.830</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.748</td>\n",
       "      <td>0.751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The Queen won ...</th>\n",
       "      <td>0.866</td>\n",
       "      <td>0.748</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The Woman won ...</th>\n",
       "      <td>0.712</td>\n",
       "      <td>0.751</td>\n",
       "      <td>0.803</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   The King won ...  The Man won ...  The Queen won ...  \\\n",
       "The King won ...              1.000            0.830              0.866   \n",
       "The Man won ...               0.830            1.000              0.748   \n",
       "The Queen won ...             0.866            0.748              1.000   \n",
       "The Woman won ...             0.712            0.751              0.803   \n",
       "\n",
       "                   The Woman won ...  \n",
       "The King won ...               0.712  \n",
       "The Man won ...                0.751  \n",
       "The Queen won ...              0.803  \n",
       "The Woman won ...              1.000  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from typing import List\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "HF_EMBEDDING_MODEL = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
    ")\n",
    "\n",
    "\n",
    "def generate_embeddings(contents: List[str], embedding_model=HF_EMBEDDING_MODEL):\n",
    "    \"\"\"\n",
    "    Generate embeddings for the given content using the Google Gemini model.\n",
    "    \"\"\"\n",
    "    response = embedding_model.embed_documents(contents)\n",
    "    return np.array(response)\n",
    "\n",
    "\n",
    "statements = [\n",
    "    'The King won the battle but lost the war.',\n",
    "    'The Man won the battle but lost the war.',\n",
    "    'The Queen won the battle but lost the war.',\n",
    "    'The Woman won the battle but lost the war.',\n",
    "]\n",
    "\n",
    "all_embeddings = generate_embeddings(statements)\n",
    "\n",
    "similarity = cosine_similarity(all_embeddings, all_embeddings)\n",
    "\n",
    "_statements = [statement.replace(\n",
    "    'the battle but lost the war.', '...') for statement in statements]\n",
    "\n",
    "df = pd.DataFrame(similarity, columns=_statements)\n",
    "\n",
    "df.index = _statements\n",
    "\n",
    "df.round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Searching for similar vectors using Cosine Similarity\n",
    "\n",
    "In the realm of modern information retrieval and recommendation systems, **vector embeddings** allow us to represent items (like text documents, images, or user preferences) as numerical vectors in a high-dimensional space. Once text is converted into these meaningful vector representations, the task of finding \"similar\" items transforms into a geometric problem: identifying vectors that are \"close\" to each other in this space. Among various distance or similarity metrics, **Cosine Similarity** stands out as a popular and effective choice for this purpose.\n",
    "\n",
    "### **The Role of Cosine Similarity**\n",
    "\n",
    "Cosine Similarity measures the cosine of the angle between two non-zero vectors. It determines whether two vectors are pointing in roughly the same direction, which indicates semantic similarity, regardless of their magnitude (length). A cosine similarity score ranges from \\-1 to 1:\n",
    "\n",
    "* **1:** Indicates identical direction (maximum similarity).  \n",
    "* **0:** Indicates orthogonality (no correlation).  \n",
    "* **\\-1:** Indicates diametrically opposite direction (maximum dissimilarity).\n",
    "\n",
    "The formula for cosine similarity between two vectors A and B is:\n",
    "\n",
    "$$\n",
    "\\text{Cosine Similarity}(A, B) = \\frac{A \\cdot B}{||A|| \\cdot ||B||}\n",
    "$$\n",
    "\n",
    "Here, A⋅B is the dot product of the vectors, and ∣∣A∣∣ and ∣∣B∣∣ are their respective magnitudes (Euclidean norms).\n",
    "\n",
    "### **Searching for Similar Vectors**\n",
    "\n",
    "The process of searching for similar vectors using cosine similarity typically involves:\n",
    "\n",
    "1. **Embedding Generation:** A query (e.g., a search phrase) is first converted into its corresponding vector embedding using the same model used for embedding the documents or items in your database.  \n",
    "2. **Similarity Calculation:** This query vector is then compared against the pre-computed embedding vectors of all documents or items in your collection. For each comparison, a cosine similarity score is calculated.  \n",
    "3. **Ranking:** The documents/items are then ranked in descending order based on their cosine similarity scores, with those having the highest positive scores considered most similar and thus most relevant to the query.\n",
    "\n",
    "This approach allows for semantic search, where results are based on meaning rather than just keyword matching, making it powerful for tasks like question answering, content recommendation, and plagiarism detection.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.722, 'The Man won the battle but lost the war.'),\n",
       " (0.618, 'The King won the battle but lost the war.'),\n",
       " (0.583, 'The Woman won the battle but lost the war.'),\n",
       " (0.568, 'The Queen won the battle but lost the war.')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sq = 'The Soldier lost all wars'\n",
    "search_embedding = generate_embeddings([sq])\n",
    "\n",
    "similarity = cosine_similarity(\n",
    "    search_embedding.reshape(1, -1), all_embeddings\n",
    ")\n",
    "\n",
    "scores = [(score, statement)\n",
    "          for score, statement in zip(similarity[0].round(3), statements)]\n",
    "\n",
    "best_matches = sorted(scores, reverse=True, key=lambda x: x[0])\n",
    "\n",
    "best_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1983</th>\n",
       "      <td>Finding Your Way, Courtesy of Machine Learning</td>\n",
       "      <td>0.583221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1449</th>\n",
       "      <td>Machine Learning In JavaScript</td>\n",
       "      <td>0.561169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1780</th>\n",
       "      <td>How can machine learning help stock investment?</td>\n",
       "      <td>0.536195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>Parallelizing Machine Learning Algorithms</td>\n",
       "      <td>0.524660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981</th>\n",
       "      <td>Exploring the Efficacy of Machine Learning in ...</td>\n",
       "      <td>0.519362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>675</th>\n",
       "      <td>Can a machine learn to teach?</td>\n",
       "      <td>0.519019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1359</th>\n",
       "      <td>Can Machines Learn Genres</td>\n",
       "      <td>0.517664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1225</th>\n",
       "      <td>Machine Learning in Stock Price Trend Forecasting</td>\n",
       "      <td>0.505323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>An Empirical Study of Machine Learning Techniq...</td>\n",
       "      <td>0.504424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2240</th>\n",
       "      <td>Implementing Machine Learning to Earthquake En...</td>\n",
       "      <td>0.502205</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  similarity\n",
       "1983     Finding Your Way, Courtesy of Machine Learning    0.583221\n",
       "1449                     Machine Learning In JavaScript    0.561169\n",
       "1780    How can machine learning help stock investment?    0.536195\n",
       "606           Parallelizing Machine Learning Algorithms    0.524660\n",
       "1981  Exploring the Efficacy of Machine Learning in ...    0.519362\n",
       "675                       Can a machine learn to teach?    0.519019\n",
       "1359                          Can Machines Learn Genres    0.517664\n",
       "1225  Machine Learning in Stock Price Trend Forecasting    0.505323\n",
       "413   An Empirical Study of Machine Learning Techniq...    0.504424\n",
       "2240  Implementing Machine Learning to Earthquake En...    0.502205"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Vector Based Search Engine\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "tqdm.pandas(desc=\"Generating embeddings\")\n",
    "\n",
    "\n",
    "def search(\n",
    "        query: str,\n",
    "        vector_database: pd.DataFrame,\n",
    "        number_of_results: int = 10,\n",
    "        embedding_model=HF_EMBEDDING_MODEL\n",
    "):\n",
    "    \"\"\"\n",
    "    Search for the most similar content in the vector database.\n",
    "    \"\"\"\n",
    "    search_embedding = generate_embeddings(\n",
    "        [query],\n",
    "        embedding_model=embedding_model\n",
    "    )[0]\n",
    "    results = vector_database.apply(\n",
    "        lambda x: cosine_similarity(\n",
    "            x.embedding.reshape(1, -1), search_embedding.reshape(1, -1)\n",
    "        )[0][0], axis=1\n",
    "    ).sort_values(ascending=False).head(number_of_results)\n",
    "\n",
    "    return pd.DataFrame(\n",
    "        {\n",
    "            'text': vector_database.iloc[results.index].text,\n",
    "            'similarity': results.values,\n",
    "        }\n",
    "    )\n",
    "\n",
    "\n",
    "# Build In Memory Vector Database\n",
    "vector_database = pd.DataFrame({'text': corpus.text, 'embedding': [\n",
    "    i for i in generate_embeddings(corpus.text)]})\n",
    "\n",
    "# Vector Based Search\n",
    "\n",
    "results = search(query=search_query, vector_database=vector_database)\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Vector databases** are a specialized type of database designed specifically to store, manage, and efficiently query **vector embeddings**. Unlike traditional relational or NoSQL databases that excel at storing structured data or documents and querying by exact matches or specific attributes, vector databases are optimized for **similarity search** in high-dimensional vector spaces.\n",
    "\n",
    "The need for vector databases arose with the proliferation of vector embeddings in AI applications. As text, images, audio, and other data types are converted into dense numerical vectors that capture their semantic meaning, there's a critical requirement to quickly find vectors (and thus the underlying data) that are \"similar\" to a given query vector. Traditional databases are not built for this kind of approximate nearest neighbor (ANN) search, which involves computing distances or similarities between many vectors.\n",
    "\n",
    "Vector databases employ advanced indexing algorithms (like HNSW \\- Hierarchical Navigable Small Worlds, or IVF \\- Inverted File Index) to organize these embeddings. When a query vector is submitted, the database rapidly identifies vectors dk​ from its stored collection $D=d_1​,d_2​,…,d_N​$ that are most similar to q. The objective is often to find $d_k​ \\in D$ such that $Similarity(q,dk​)$ is maximized (or $Distance(q,dk​)$ is minimized).\n",
    "\n",
    "These databases are foundational to modern AI systems, powering applications like:\n",
    "\n",
    "* **Semantic Search:** Finding results based on meaning, not just keywords.  \n",
    "* **Retrieval-Augmented Generation (RAG):** Providing LLMs with relevant context.  \n",
    "* **Recommendation Systems:** Suggesting items similar to what a user likes.  \n",
    "* **Anomaly Detection:** Identifying outliers in data.\n",
    "\n",
    "By enabling lightning-fast similarity lookups for millions or billions of vectors, vector databases unlock the true potential of embedding-based AI applications.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Qdrant Vector Database\n",
    "\n",
    "from qdrant_client import QdrantClient\n",
    "import qdrant_client\n",
    "from qdrant_client.http.models import Distance\n",
    "from qdrant_client.http.models import VectorParams\n",
    "from qdrant_client.http.models import CollectionStatus\n",
    "from qdrant_client.http.models import PointStruct\n",
    "\n",
    "# qdrant_client = QdrantClient(\n",
    "#     url='http://localhost:6333',  # url version\n",
    "#     # http_port=6333,\n",
    "# )\n",
    "qdrant_client = QdrantClient(location=':memory:')\n",
    "\n",
    "if qdrant_client.collection_exists(\"ml_ideas\"):\n",
    "    print('cleaning existing collection')\n",
    "    qdrant_client.delete_collection(\"ml_ideas\")\n",
    "\n",
    "qdrant_client.create_collection(\n",
    "    collection_name=\"ml_ideas\",\n",
    "    vectors_config=VectorParams(\n",
    "        size=768,\n",
    "        distance=Distance.COSINE\n",
    "    ),\n",
    ")\n",
    "\n",
    "qdrant_client.get_collection(\"ml_ideas\").status == CollectionStatus.GREEN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting raw string data, such as text documents, articles, or even short sentences, into a format that can be efficiently stored and queried for semantic similarity is a crucial step in building intelligent AI applications. This is where the process of generating **vector embeddings** and storing them in a **vector database** like Qdrant comes into play.\n",
    "\n",
    "Traditional databases are not optimized for searching based on the *meaning* of text. They excel at exact keyword matches or structured queries. However, with the rise of large language models (LLMs) and semantic search, the ability to find information based on contextual relevance, even if exact keywords aren't present, has become paramount.\n",
    "\n",
    "The process typically involves:\n",
    "\n",
    "1. **Embedding Generation:**  \n",
    "   * The string data is passed through an **embedding model** (e.g., a dedicated text embedding model from Google, OpenAI, Hugging Face, or even an LLM itself if it provides embedding capabilities).  \n",
    "   * This model transforms the unstructured string into a high-dimensional numerical vector, where semantically similar strings are mapped to vectors that are geometrically close in the embedding space. For instance, the phrase \"solar panel efficiency\" and \"improving photovoltaic output\" would yield vectors that are very close to each other, despite using different words.  \n",
    "   * Each string is converted into its corresponding embedding vector VS​=$v_1​,v_2,…,v_n​$, where n is the dimensionality of the embedding space (e.g., 768, 1024, or more).  \n",
    "2. **Storage in a Vector Database (e.g., Qdrant):**  \n",
    "   * Once the embeddings are generated, they are stored in a specialized vector database. Qdrant is an excellent example of such a database, designed for high-performance similarity search.  \n",
    "   * In Qdrant, you create a \"collection\" (similar to a table) where each \"point\" (record) consists of the vector embedding and optionally, an associated payload (the original string data or metadata related to it).  \n",
    "   * Qdrant then uses efficient Approximate Nearest Neighbor (ANN) algorithms (like HNSW) to index these vectors. This allows for extremely fast searches for vectors that are closest to a given query vector.\n",
    "\n",
    "When a user performs a semantic search, their query string is also converted into an embedding. This query vector is then sent to Qdrant, which quickly finds and returns the most similar document vectors based on metrics like Cosine Similarity:\n",
    "\n",
    "$Cosine Similarity(VQ​,VD​)=∣∣VQ​∣∣⋅∣∣VD​∣∣VQ​⋅VD​​$\n",
    "\n",
    "where VQ​ is the query vector and VD​ is the document vector.\n",
    "\n",
    "\n",
    "This returned set of similar vectors points back to the original string data in the payload, enabling powerful semantic search, retrieval-augmented generation (RAG), and recommendation systems.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Finding Your Way, Courtesy of Machine Learning',\n",
       " 'Machine Learning In JavaScript',\n",
       " 'How can machine learning help stock investment?',\n",
       " 'Parallelizing Machine Learning Algorithms',\n",
       " 'Exploring the Efficacy of Machine Learning in General Game Playing',\n",
       " 'Can a machine learn to teach?',\n",
       " 'Can Machines Learn Genres',\n",
       " 'Machine Learning in Stock Price Trend Forecasting',\n",
       " 'An Empirical Study of Machine Learning Techniques used for Enhancer Classification',\n",
       " 'Implementing Machine Learning to Earthquake Engineering']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inserting data into qdrant\n",
    "\n",
    "from langchain_qdrant import Qdrant  # Qdrant Vector Store Wrapper\n",
    "\n",
    "vector_store = Qdrant.from_texts(\n",
    "    corpus.text,\n",
    "    HF_EMBEDDING_MODEL,\n",
    "    collection_name=\"ml_ideas\",\n",
    "    location=':memory:',\n",
    ")\n",
    "\n",
    "results = vector_store.search(\n",
    "    query=search_query,\n",
    "    search_type=\"similarity\",\n",
    "    k=10\n",
    ")\n",
    "\n",
    "[\n",
    "    result.page_content\n",
    "    for result in results\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimensionality of Vector Embeddings\n",
    "\n",
    "The dimensionality of a vector embedding refers to the number of numerical values (or features) in the vector that represents a piece of data, such as text. For instance, a 768-dimensional embedding is an array of 768 numbers. This dimension size significantly impacts the effectiveness and efficiency of similarity search operations.\n",
    "\n",
    "Lower-dimensional embeddings (e.g., 64, 128, 256\\) are computationally efficient, requiring less memory storage and leading to faster search queries. They are suitable for simpler datasets or tasks where fine-grained semantic distinctions are less critical. However, they might lose some nuanced information during compression, potentially reducing search accuracy for complex relationships, as they have fewer \"slots\" to encode detailed meaning.\n",
    "\n",
    "Higher-dimensional embeddings (e.g., 768, 1024, 1536, or more) can capture more complex and subtle semantic relationships within the data. This often leads to higher search accuracy and relevance. However, they come at a cost: increased memory consumption, higher computational overhead for distance calculations (like Cosine Similarity), and slower search speeds. Extremely high dimensions can also lead to the \"curse of dimensionality,\" where data becomes sparse, and distances between vectors lose their meaningful distinction.\n",
    "\n",
    "The goal is to find an optimal balance where the dimension is sufficient to capture necessary semantic information for accurate search without incurring excessive computational burden. The effectiveness of search relies on being able to accurately measure similarity between vectors, often using:\n",
    "\n",
    "$Cosine Similarity(A,B)=∣∣A∣∣⋅∣∣B∣∣A⋅B​$\n",
    "\n",
    "Choosing the right dimensionality depends on the specific use case, the complexity of the data, and available computational resources.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64 384 768\n"
     ]
    }
   ],
   "source": [
    "# load different dimension embedding models\n",
    "\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "model_768 = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/LaBSE\",\n",
    ")\n",
    "\n",
    "model_384 = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
    ")\n",
    "\n",
    "model_64 = HuggingFaceEmbeddings(\n",
    "    model_name=\"ClovenDoug/tiny_64_all-MiniLM-L6-v2\",\n",
    ")\n",
    "\n",
    "\n",
    "v64, v384, v768 = (\n",
    "    model_64.embed_query(search_query),\n",
    "    model_384.embed_query(search_query),\n",
    "    model_768.embed_query(search_query),\n",
    ")\n",
    "\n",
    "print(len(v64), len(v384), len(v768))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Can a machine learn to teach?',\n",
       " 'Machine Learning In JavaScript',\n",
       " 'A Machine Learning Approach for Future Career Planning',\n",
       " 'Motor Skill Learning',\n",
       " 'Automated Curriculum Learning',\n",
       " 'Modeling Protein Interactions Using Bayesian Networks',\n",
       " 'Exploring Potential for Machine Learning on Dataset about K-12 Teacher Professional Development',\n",
       " 'Learning to Test',\n",
       " 'What Can You Learn From Accelerometer Data',\n",
       " 'Adversarial Machine Learning against Keystroke Dynamics']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 64 dimensional embedding\n",
    "\n",
    "vector_store = Qdrant.from_texts(\n",
    "    corpus.text,\n",
    "    model_64,\n",
    "    collection_name=\"ml_ideas_64\",\n",
    "    location=':memory:',\n",
    ")\n",
    "\n",
    "results = vector_store.search(\n",
    "    query=search_query,\n",
    "    search_type=\"similarity\",\n",
    "    k=10\n",
    ")\n",
    "\n",
    "[\n",
    "    result.page_content\n",
    "    for result in results\n",
    "]\n",
    "\n",
    "# Output:\n",
    "# ['Can a machine learn to teach?',\n",
    "#  'Machine Learning In JavaScript',\n",
    "#  'A Machine Learning Approach for Future Career Planning',\n",
    "#  'Motor Skill Learning',\n",
    "#  'Automated Curriculum Learning',\n",
    "#  'Modeling Protein Interactions Using Bayesian Networks',\n",
    "#  'Exploring Potential for Machine Learning on Dataset about K-12 Teacher Professional Development',\n",
    "#  'Learning to Test',\n",
    "#  'What Can You Learn From Accelerometer Data',\n",
    "#  'Adversarial Machine Learning against Keystroke Dynamics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Finding Your Way, Courtesy of Machine Learning',\n",
       " 'Machine Learning In JavaScript',\n",
       " 'How can machine learning help stock investment?',\n",
       " 'Parallelizing Machine Learning Algorithms',\n",
       " 'Exploring the Efficacy of Machine Learning in General Game Playing',\n",
       " 'Can a machine learn to teach?',\n",
       " 'Can Machines Learn Genres',\n",
       " 'Machine Learning in Stock Price Trend Forecasting',\n",
       " 'An Empirical Study of Machine Learning Techniques used for Enhancer Classification',\n",
       " 'Implementing Machine Learning to Earthquake Engineering']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 384 dimensional embedding\n",
    "vector_store = Qdrant.from_texts(\n",
    "    corpus.text,\n",
    "    model_384,\n",
    "    collection_name=\"ml_ideas_384\",\n",
    "    location=':memory:',\n",
    ")\n",
    "\n",
    "results = vector_store.search(\n",
    "    query=search_query,\n",
    "    search_type=\"similarity\",\n",
    "    k=10\n",
    ")\n",
    "\n",
    "[\n",
    "    result.page_content\n",
    "    for result in results\n",
    "]\n",
    "\n",
    "# Output:\n",
    "# ['Finding Your Way, Courtesy of Machine Learning',\n",
    "#  'Machine Learning In JavaScript',\n",
    "#  'How can machine learning help stock investment?',\n",
    "#  'Parallelizing Machine Learning Algorithms',\n",
    "#  'Exploring the Efficacy of Machine Learning in General Game Playing',\n",
    "#  'Can a machine learn to teach?',\n",
    "#  'Can Machines Learn Genres',\n",
    "#  'Machine Learning in Stock Price Trend Forecasting',\n",
    "#  'An Empirical Study of Machine Learning Techniques used for Enhancer Classification',\n",
    "#  'Implementing Machine Learning to Earthquake Engineering']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Can a machine learn to teach?',\n",
       " 'How can machine learning help stock investment?',\n",
       " 'A study of ensemble methods in machine learning',\n",
       " 'Better Reading Levels through Machine Learning',\n",
       " 'How well do people learn?',\n",
       " 'Machine Learning Techniques for Optimal Sampling-Based Motion Planning',\n",
       " 'Machine Learning Methods for News Popularity Prediction',\n",
       " 'The Price is Right? Estimating Medical Costs with Machine Learning',\n",
       " 'Optimizing Leakage Power using Machine Learning',\n",
       " 'Improving Tictoc With Machine Learning']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 768 dimensional embedding\n",
    "vector_store = Qdrant.from_texts(\n",
    "    corpus.text,\n",
    "    model_768,\n",
    "    collection_name=\"ml_ideas_768\",\n",
    "    location=':memory:',\n",
    ")\n",
    "\n",
    "results = vector_store.search(\n",
    "    query=search_query,\n",
    "    search_type=\"similarity\",\n",
    "    k=10\n",
    ")\n",
    "\n",
    "[\n",
    "    result.page_content\n",
    "    for result in results\n",
    "]\n",
    "\n",
    "# Output:\n",
    "# ['Can a machine learn to teach?',\n",
    "#  'How can machine learning help stock investment?',\n",
    "#  'A study of ensemble methods in machine learning',\n",
    "#  'Better Reading Levels through Machine Learning',\n",
    "#  'How well do people learn?',\n",
    "#  'Machine Learning Techniques for Optimal Sampling-Based Motion Planning',\n",
    "#  'Machine Learning Methods for News Popularity Prediction',\n",
    "#  'The Price is Right? Estimating Medical Costs with Machine Learning',\n",
    "#  'Optimizing Leakage Power using Machine Learning',\n",
    "#  'Improving Tictoc With Machine Learning']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing a Vector Database\n",
    "\n",
    "Selecting the appropriate vector database is a critical decision that profoundly impacts the performance, scalability, cost, and maintainability of your AI application, especially when building solutions like semantic search engines or Retrieval-Augmented Generation (RAG) systems. There's no one-size-fits-all solution; the \"right\" choice depends heavily on your specific needs.\n",
    "\n",
    "Key factors to consider include:\n",
    "\n",
    "1. **Scale and Data Volume:**  \n",
    "   * How many vectors do you need to store (millions, billions, trillions)?  \n",
    "   * What is the dimensionality of your embeddings (e.g., 384, 768, 1536)?  \n",
    "   * What is your expected growth rate? These factors dictate the storage and indexing capabilities required.  \n",
    "2. **Performance Requirements:**  \n",
    "   * **Query Latency:** How quickly do you need search results (e.g., milliseconds for real-time applications)?  \n",
    "   * **Throughput:** How many queries per second (QPS) do you anticipate?  \n",
    "   * **Indexing Speed:** How fast can new data be added and indexed? High-performance demands often necessitate specialized indexing algorithms and optimized architectures.  \n",
    "3. **Features and Functionality:**  \n",
    "   * **Filtering and Metadata:** Can you filter searches based on associated metadata (e.g., search for documents from a specific date range or category)?  \n",
    "   * **Hybrid Search:** Does it support combining vector search with keyword search?  \n",
    "   * **Scalability Model:** Is it horizontally scalable?  \n",
    "   * **Deployment Options:** Cloud-managed service, self-hosted, on-premise?  \n",
    "   * **Data Consistency & Durability:** What are the guarantees for data integrity and availability?  \n",
    "4. **Cost:**  \n",
    "   * This includes infrastructure costs (for self-hosting), managed service fees, and operational overhead.  \n",
    "   * Consider the total cost of ownership, not just licensing fees.  \n",
    "5. **Ecosystem and Integrations:**  \n",
    "   * Does the database integrate well with your existing tech stack, particularly with popular NLP frameworks like LangChain or LlamaIndex, and your chosen embedding models?  \n",
    "   * What community support or enterprise support is available?\n",
    "\n",
    "Popular choices include dedicated vector databases like **Pinecone** (managed service), **Weaviate**, **Qdrant**, and **Milvus** (open-source, self-hostable options). Each offers a different set of trade-offs across these criteria. Thorough evaluation, often involving prototyping with a representative dataset, is crucial to ensure the selected database aligns with both your current needs and future growth.\n",
    "\n",
    "*Note: The \"choosing\" process itself doesn't inherently involve specific mathematical equations beyond evaluating performance metrics like latency or throughput, which are outcomes of the database's internal algorithms.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6da79293ff7f40fb808eb50002c3ec80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Documents:   0%|          | 0/6871 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RecipeName</th>\n",
       "      <th>TranslatedRecipeName</th>\n",
       "      <th>Ingredients</th>\n",
       "      <th>TranslatedIngredients</th>\n",
       "      <th>PrepTimeInMins</th>\n",
       "      <th>CookTimeInMins</th>\n",
       "      <th>TotalTimeInMins</th>\n",
       "      <th>Servings</th>\n",
       "      <th>Cuisine</th>\n",
       "      <th>Course</th>\n",
       "      <th>Diet</th>\n",
       "      <th>Instructions</th>\n",
       "      <th>TranslatedInstructions</th>\n",
       "      <th>URL</th>\n",
       "      <th>ComplexityLevel</th>\n",
       "      <th>MainIngredient</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Srno</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Masala Karela Recipe</td>\n",
       "      <td>Masala Karela Recipe</td>\n",
       "      <td>6 Karela (Bitter Gourd/ Pavakkai) - deseeded,S...</td>\n",
       "      <td>6 Karela (Bitter Gourd/ Pavakkai) - deseeded,S...</td>\n",
       "      <td>15</td>\n",
       "      <td>30</td>\n",
       "      <td>45</td>\n",
       "      <td>6</td>\n",
       "      <td>Indian</td>\n",
       "      <td>Side Dish</td>\n",
       "      <td>Diabetic Friendly</td>\n",
       "      <td>To begin making the Masala Karela Recipe,de-se...</td>\n",
       "      <td>To begin making the Masala Karela Recipe,de-se...</td>\n",
       "      <td>https://www.archanaskitchen.com/masala-karela-...</td>\n",
       "      <td>Hard</td>\n",
       "      <td>deseeded</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>टमाटर पुलियोगरे रेसिपी - Spicy Tomato Rice (Re...</td>\n",
       "      <td>Spicy Tomato Rice (Recipe)</td>\n",
       "      <td>2-1/2 कप चावल - पका ले,3 टमाटर,3 छोटा चमच्च बी...</td>\n",
       "      <td>2-1 / 2 cups rice - cooked, 3 tomatoes, 3 teas...</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>South Indian Recipes</td>\n",
       "      <td>Main Course</td>\n",
       "      <td>Vegetarian</td>\n",
       "      <td>टमाटर पुलियोगरे बनाने के लिए सबसे पहले टमाटर क...</td>\n",
       "      <td>To make tomato puliogere, first cut the tomato...</td>\n",
       "      <td>http://www.archanaskitchen.com/spicy-tomato-ri...</td>\n",
       "      <td>Hard</td>\n",
       "      <td>cooked</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ragi Semiya Upma Recipe - Ragi Millet Vermicel...</td>\n",
       "      <td>Ragi Semiya Upma Recipe - Ragi Millet Vermicel...</td>\n",
       "      <td>1-1/2 cups Rice Vermicelli Noodles (Thin),1 On...</td>\n",
       "      <td>1-1/2 cups Rice Vermicelli Noodles (Thin),1 On...</td>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>South Indian Recipes</td>\n",
       "      <td>South Indian Breakfast</td>\n",
       "      <td>High Protein Vegetarian</td>\n",
       "      <td>To begin making the Ragi Vermicelli Recipe, fi...</td>\n",
       "      <td>To begin making the Ragi Vermicelli Recipe, fi...</td>\n",
       "      <td>http://www.archanaskitchen.com/ragi-vermicelli...</td>\n",
       "      <td>Hard</td>\n",
       "      <td>(Thin)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gongura Chicken Curry Recipe - Andhra Style Go...</td>\n",
       "      <td>Gongura Chicken Curry Recipe - Andhra Style Go...</td>\n",
       "      <td>500 grams Chicken,2 Onion - chopped,1 Tomato -...</td>\n",
       "      <td>500 grams Chicken,2 Onion - chopped,1 Tomato -...</td>\n",
       "      <td>15</td>\n",
       "      <td>30</td>\n",
       "      <td>45</td>\n",
       "      <td>4</td>\n",
       "      <td>Andhra</td>\n",
       "      <td>Lunch</td>\n",
       "      <td>Non Vegeterian</td>\n",
       "      <td>To begin making Gongura Chicken Curry Recipe f...</td>\n",
       "      <td>To begin making Gongura Chicken Curry Recipe f...</td>\n",
       "      <td>http://www.archanaskitchen.com/gongura-chicken...</td>\n",
       "      <td>Hard</td>\n",
       "      <td>Chicken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>आंध्रा स्टाइल आलम पचड़ी रेसिपी - Adrak Chutney ...</td>\n",
       "      <td>Andhra Style Alam Pachadi Recipe - Adrak Chutn...</td>\n",
       "      <td>1 बड़ा चमच्च चना दाल,1 बड़ा चमच्च सफ़ेद उरद दाल,2...</td>\n",
       "      <td>1 tablespoon chana dal, 1 tablespoon white ura...</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>Andhra</td>\n",
       "      <td>South Indian Breakfast</td>\n",
       "      <td>Vegetarian</td>\n",
       "      <td>आंध्रा स्टाइल आलम पचड़ी बनाने के लिए सबसे पहले ...</td>\n",
       "      <td>To make Andhra Style Alam Pachadi, first heat ...</td>\n",
       "      <td>https://www.archanaskitchen.com/andhra-style-a...</td>\n",
       "      <td>Hard</td>\n",
       "      <td>dal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14073</th>\n",
       "      <td>गोअन मशरुम जकुटी रेसिपी - Goan Mushroom Xacuti...</td>\n",
       "      <td>Goan Mushroom Xacuti Recipe</td>\n",
       "      <td>20 बटन मशरुम,2 प्याज - काट ले,1 टमाटर - बारीक ...</td>\n",
       "      <td>20 बटन मशरुम,2 प्याज - काट ले,1 टमाटर - बारीक ...</td>\n",
       "      <td>15</td>\n",
       "      <td>45</td>\n",
       "      <td>60</td>\n",
       "      <td>4</td>\n",
       "      <td>Goan Recipes</td>\n",
       "      <td>Lunch</td>\n",
       "      <td>Vegetarian</td>\n",
       "      <td>गोअन मशरुम जकुटी रेसिपी बनाने के लिए सबसे पहले...</td>\n",
       "      <td>गोअन मशरुम जकुटी रेसिपी बनाने के लिए सबसे पहले...</td>\n",
       "      <td>https://www.archanaskitchen.com/goan-mushroom-...</td>\n",
       "      <td>Hard</td>\n",
       "      <td>मशरुम</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14107</th>\n",
       "      <td>शकरकंदी और मेथी का पराठा रेसिपी - Sweet Potato...</td>\n",
       "      <td>Sweet Potato &amp; Methi Stuffed Paratha Recipe</td>\n",
       "      <td>1 बड़ा चम्मच तेल,1 कप गेहूं का आटा,नमक - स्वाद ...</td>\n",
       "      <td>1 बड़ा चम्मच तेल,1 कप गेहूं का आटा,नमक - स्वाद ...</td>\n",
       "      <td>30</td>\n",
       "      <td>60</td>\n",
       "      <td>90</td>\n",
       "      <td>4</td>\n",
       "      <td>North Indian Recipes</td>\n",
       "      <td>North Indian Breakfast</td>\n",
       "      <td>Diabetic Friendly</td>\n",
       "      <td>शकरकंदी और मेथी का पराठा रेसिपी बनाने के लिए स...</td>\n",
       "      <td>शकरकंदी और मेथी का पराठा रेसिपी बनाने के लिए स...</td>\n",
       "      <td>https://www.archanaskitchen.com/sweet-potato-m...</td>\n",
       "      <td>Hard</td>\n",
       "      <td>तेल</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14165</th>\n",
       "      <td>Ullikadala Pulusu Recipe | Spring Onion Curry</td>\n",
       "      <td>Ullikadala Pulusu Recipe | Spring Onion Curry</td>\n",
       "      <td>150 grams Spring Onion (Bulb &amp; Greens) - chopp...</td>\n",
       "      <td>150 grams Spring Onion (Bulb &amp; Greens) - chopp...</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>Andhra</td>\n",
       "      <td>Side Dish</td>\n",
       "      <td>Vegetarian</td>\n",
       "      <td>To begin making Ullikadala Pulusu Recipe | Spr...</td>\n",
       "      <td>To begin making Ullikadala Pulusu Recipe | Spr...</td>\n",
       "      <td>https://www.archanaskitchen.com/ullikadala-pul...</td>\n",
       "      <td>Hard</td>\n",
       "      <td>chopped</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14167</th>\n",
       "      <td>Kashmiri Style Kokur Yakhni Recipe-Chicken Coo...</td>\n",
       "      <td>Kashmiri Style Kokur Yakhni Recipe-Chicken Coo...</td>\n",
       "      <td>1 kg Chicken - medium pieces,1/2 cup Mustard o...</td>\n",
       "      <td>1 kg Chicken - medium pieces,1/2 cup Mustard o...</td>\n",
       "      <td>30</td>\n",
       "      <td>45</td>\n",
       "      <td>75</td>\n",
       "      <td>4</td>\n",
       "      <td>Kashmiri</td>\n",
       "      <td>Lunch</td>\n",
       "      <td>Non Vegeterian</td>\n",
       "      <td>To begin making the Kashmiri Kokur Yakhni reci...</td>\n",
       "      <td>To begin making the Kashmiri Kokur Yakhni reci...</td>\n",
       "      <td>http://www.archanaskitchen.com/kashmiri-kokur-...</td>\n",
       "      <td>Hard</td>\n",
       "      <td>pieces</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14211</th>\n",
       "      <td>नवरंग दाल रेसिपी - Navrang Dal Recipe</td>\n",
       "      <td>Navrang Dal Recipe</td>\n",
       "      <td>2 बड़े चम्मच हरी मूंग दाल,2 बड़े चम्मच सफ़ेद उरद ...</td>\n",
       "      <td>2 बड़े चम्मच हरी मूंग दाल,2 बड़े चम्मच सफ़ेद उरद ...</td>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>North Indian Recipes</td>\n",
       "      <td>Lunch</td>\n",
       "      <td>High Protein Vegetarian</td>\n",
       "      <td>नवरंग दाल रेसिपी  बनाने के लिए सबसे पहले सारी ...</td>\n",
       "      <td>नवरंग दाल रेसिपी  बनाने के लिए सबसे पहले सारी ...</td>\n",
       "      <td>https://www.archanaskitchen.com/navrang-dal-re...</td>\n",
       "      <td>Hard</td>\n",
       "      <td>दाल</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6871 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              RecipeName  \\\n",
       "Srno                                                       \n",
       "1                                   Masala Karela Recipe   \n",
       "2      टमाटर पुलियोगरे रेसिपी - Spicy Tomato Rice (Re...   \n",
       "3      Ragi Semiya Upma Recipe - Ragi Millet Vermicel...   \n",
       "4      Gongura Chicken Curry Recipe - Andhra Style Go...   \n",
       "5      आंध्रा स्टाइल आलम पचड़ी रेसिपी - Adrak Chutney ...   \n",
       "...                                                  ...   \n",
       "14073  गोअन मशरुम जकुटी रेसिपी - Goan Mushroom Xacuti...   \n",
       "14107  शकरकंदी और मेथी का पराठा रेसिपी - Sweet Potato...   \n",
       "14165      Ullikadala Pulusu Recipe | Spring Onion Curry   \n",
       "14167  Kashmiri Style Kokur Yakhni Recipe-Chicken Coo...   \n",
       "14211              नवरंग दाल रेसिपी - Navrang Dal Recipe   \n",
       "\n",
       "                                    TranslatedRecipeName  \\\n",
       "Srno                                                       \n",
       "1                                   Masala Karela Recipe   \n",
       "2                             Spicy Tomato Rice (Recipe)   \n",
       "3      Ragi Semiya Upma Recipe - Ragi Millet Vermicel...   \n",
       "4      Gongura Chicken Curry Recipe - Andhra Style Go...   \n",
       "5      Andhra Style Alam Pachadi Recipe - Adrak Chutn...   \n",
       "...                                                  ...   \n",
       "14073                        Goan Mushroom Xacuti Recipe   \n",
       "14107        Sweet Potato & Methi Stuffed Paratha Recipe   \n",
       "14165      Ullikadala Pulusu Recipe | Spring Onion Curry   \n",
       "14167  Kashmiri Style Kokur Yakhni Recipe-Chicken Coo...   \n",
       "14211                                 Navrang Dal Recipe   \n",
       "\n",
       "                                             Ingredients  \\\n",
       "Srno                                                       \n",
       "1      6 Karela (Bitter Gourd/ Pavakkai) - deseeded,S...   \n",
       "2      2-1/2 कप चावल - पका ले,3 टमाटर,3 छोटा चमच्च बी...   \n",
       "3      1-1/2 cups Rice Vermicelli Noodles (Thin),1 On...   \n",
       "4      500 grams Chicken,2 Onion - chopped,1 Tomato -...   \n",
       "5      1 बड़ा चमच्च चना दाल,1 बड़ा चमच्च सफ़ेद उरद दाल,2...   \n",
       "...                                                  ...   \n",
       "14073  20 बटन मशरुम,2 प्याज - काट ले,1 टमाटर - बारीक ...   \n",
       "14107  1 बड़ा चम्मच तेल,1 कप गेहूं का आटा,नमक - स्वाद ...   \n",
       "14165  150 grams Spring Onion (Bulb & Greens) - chopp...   \n",
       "14167  1 kg Chicken - medium pieces,1/2 cup Mustard o...   \n",
       "14211  2 बड़े चम्मच हरी मूंग दाल,2 बड़े चम्मच सफ़ेद उरद ...   \n",
       "\n",
       "                                   TranslatedIngredients  PrepTimeInMins  \\\n",
       "Srno                                                                       \n",
       "1      6 Karela (Bitter Gourd/ Pavakkai) - deseeded,S...              15   \n",
       "2      2-1 / 2 cups rice - cooked, 3 tomatoes, 3 teas...               5   \n",
       "3      1-1/2 cups Rice Vermicelli Noodles (Thin),1 On...              20   \n",
       "4      500 grams Chicken,2 Onion - chopped,1 Tomato -...              15   \n",
       "5      1 tablespoon chana dal, 1 tablespoon white ura...              10   \n",
       "...                                                  ...             ...   \n",
       "14073  20 बटन मशरुम,2 प्याज - काट ले,1 टमाटर - बारीक ...              15   \n",
       "14107  1 बड़ा चम्मच तेल,1 कप गेहूं का आटा,नमक - स्वाद ...              30   \n",
       "14165  150 grams Spring Onion (Bulb & Greens) - chopp...               5   \n",
       "14167  1 kg Chicken - medium pieces,1/2 cup Mustard o...              30   \n",
       "14211  2 बड़े चम्मच हरी मूंग दाल,2 बड़े चम्मच सफ़ेद उरद ...              10   \n",
       "\n",
       "       CookTimeInMins  TotalTimeInMins  Servings               Cuisine  \\\n",
       "Srno                                                                     \n",
       "1                  30               45         6                Indian   \n",
       "2                  10               15         3  South Indian Recipes   \n",
       "3                  30               50         4  South Indian Recipes   \n",
       "4                  30               45         4                Andhra   \n",
       "5                  20               30         4                Andhra   \n",
       "...               ...              ...       ...                   ...   \n",
       "14073              45               60         4          Goan Recipes   \n",
       "14107              60               90         4  North Indian Recipes   \n",
       "14165              10               15         2                Andhra   \n",
       "14167              45               75         4              Kashmiri   \n",
       "14211              30               40         4  North Indian Recipes   \n",
       "\n",
       "                       Course                     Diet  \\\n",
       "Srno                                                     \n",
       "1                   Side Dish        Diabetic Friendly   \n",
       "2                 Main Course               Vegetarian   \n",
       "3      South Indian Breakfast  High Protein Vegetarian   \n",
       "4                       Lunch           Non Vegeterian   \n",
       "5      South Indian Breakfast               Vegetarian   \n",
       "...                       ...                      ...   \n",
       "14073                   Lunch               Vegetarian   \n",
       "14107  North Indian Breakfast        Diabetic Friendly   \n",
       "14165               Side Dish               Vegetarian   \n",
       "14167                   Lunch           Non Vegeterian   \n",
       "14211                   Lunch  High Protein Vegetarian   \n",
       "\n",
       "                                            Instructions  \\\n",
       "Srno                                                       \n",
       "1      To begin making the Masala Karela Recipe,de-se...   \n",
       "2      टमाटर पुलियोगरे बनाने के लिए सबसे पहले टमाटर क...   \n",
       "3      To begin making the Ragi Vermicelli Recipe, fi...   \n",
       "4      To begin making Gongura Chicken Curry Recipe f...   \n",
       "5      आंध्रा स्टाइल आलम पचड़ी बनाने के लिए सबसे पहले ...   \n",
       "...                                                  ...   \n",
       "14073  गोअन मशरुम जकुटी रेसिपी बनाने के लिए सबसे पहले...   \n",
       "14107  शकरकंदी और मेथी का पराठा रेसिपी बनाने के लिए स...   \n",
       "14165  To begin making Ullikadala Pulusu Recipe | Spr...   \n",
       "14167  To begin making the Kashmiri Kokur Yakhni reci...   \n",
       "14211  नवरंग दाल रेसिपी  बनाने के लिए सबसे पहले सारी ...   \n",
       "\n",
       "                                  TranslatedInstructions  \\\n",
       "Srno                                                       \n",
       "1      To begin making the Masala Karela Recipe,de-se...   \n",
       "2      To make tomato puliogere, first cut the tomato...   \n",
       "3      To begin making the Ragi Vermicelli Recipe, fi...   \n",
       "4      To begin making Gongura Chicken Curry Recipe f...   \n",
       "5      To make Andhra Style Alam Pachadi, first heat ...   \n",
       "...                                                  ...   \n",
       "14073  गोअन मशरुम जकुटी रेसिपी बनाने के लिए सबसे पहले...   \n",
       "14107  शकरकंदी और मेथी का पराठा रेसिपी बनाने के लिए स...   \n",
       "14165  To begin making Ullikadala Pulusu Recipe | Spr...   \n",
       "14167  To begin making the Kashmiri Kokur Yakhni reci...   \n",
       "14211  नवरंग दाल रेसिपी  बनाने के लिए सबसे पहले सारी ...   \n",
       "\n",
       "                                                     URL ComplexityLevel  \\\n",
       "Srno                                                                       \n",
       "1      https://www.archanaskitchen.com/masala-karela-...            Hard   \n",
       "2      http://www.archanaskitchen.com/spicy-tomato-ri...            Hard   \n",
       "3      http://www.archanaskitchen.com/ragi-vermicelli...            Hard   \n",
       "4      http://www.archanaskitchen.com/gongura-chicken...            Hard   \n",
       "5      https://www.archanaskitchen.com/andhra-style-a...            Hard   \n",
       "...                                                  ...             ...   \n",
       "14073  https://www.archanaskitchen.com/goan-mushroom-...            Hard   \n",
       "14107  https://www.archanaskitchen.com/sweet-potato-m...            Hard   \n",
       "14165  https://www.archanaskitchen.com/ullikadala-pul...            Hard   \n",
       "14167  http://www.archanaskitchen.com/kashmiri-kokur-...            Hard   \n",
       "14211  https://www.archanaskitchen.com/navrang-dal-re...            Hard   \n",
       "\n",
       "      MainIngredient  \n",
       "Srno                  \n",
       "1           deseeded  \n",
       "2             cooked  \n",
       "3             (Thin)  \n",
       "4            Chicken  \n",
       "5                dal  \n",
       "...              ...  \n",
       "14073          मशरुम  \n",
       "14107            तेल  \n",
       "14165        chopped  \n",
       "14167         pieces  \n",
       "14211            दाल  \n",
       "\n",
       "[6871 rows x 16 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://www.kaggle.com/datasets/fajobgiua/indian-food-dataset?resource=download\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "tqdm.pandas(desc=\"Generating Documents\")\n",
    "\n",
    "df = pd.read_csv('./IndianFoodDataset.csv', ).set_index('Srno')\n",
    "\n",
    "data = df[:].progress_apply(\n",
    "    lambda x: x.to_markdown(),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "vector_store = Qdrant.from_texts(\n",
    "    data,\n",
    "    model_768,\n",
    "    collection_name=\"indian-food\",\n",
    "    location=':memory:',\n",
    ")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19529\n",
      "|                        | 10144                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |\n",
      "|:-----------------------|:------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
      "| RecipeName             | Thai Spicy Green Papaya Salad Recipe With Sweet Corn - Som Tum Khao Pod                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |\n",
      "| TranslatedRecipeName   | Thai Spicy Green Papaya Salad Recipe With Sweet Corn - Som Tum Khao Pod                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |\n",
      "| Ingredients            | 300 grams Raw papaya - grated,2 Carrots (Gajjar) - grated,1/2 cup Sweet corn - steamed,1 Tomato - thinly sliced,3 Thai Red chilli (Birds Eye Chilli) - or regular green chillies,1/2 cup Roasted Peanuts (Moongphali) - coarsely pounded or halved,1 inch Ginger - peeled and grated,2 cloves Garlic - finely chopped,2 teaspoons Light soy sauce,1 tablespoon Palm sugar - or honey,Salt - to taste                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |\n",
      "| TranslatedIngredients  | 300 grams Raw papaya - grated,2 Carrots (Gajjar) - grated,1/2 cup Sweet corn - steamed,1 Tomato - thinly sliced,3 Thai Red chilli (Birds Eye Chilli) - or regular green chillies,1/2 cup Roasted Peanuts (Moongphali) - coarsely pounded or halved,1 inch Ginger - peeled and grated,2 cloves Garlic - finely chopped,2 teaspoons Light soy sauce,1 tablespoon Palm sugar - or honey,Salt - to taste                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |\n",
      "| PrepTimeInMins         | 15                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |\n",
      "| CookTimeInMins         | 20                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |\n",
      "| TotalTimeInMins        | 35                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |\n",
      "| Servings               | 2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               |\n",
      "| Cuisine                | Thai                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |\n",
      "| Course                 | Side Dish                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |\n",
      "| Diet                   | Vegetarian                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |\n",
      "| Instructions           | To begin making the Thai Spicy Corn and Green Papaya Salad Recipe, we will first grate carrots and papaya. I personally like to use a Food Processor's Grater attachment to grate the raw green papaya and the carrots. The processor simplifies the process of making the salad. To prepare the dressing for the salad, in a pestle and mortar, add the garlic, grated ginger, chillies and lightly pound them. Add the sugar, lemon juice and soy sauce, pound with the pestle and pound again. Add half of the roasted peanuts and lightly pound along with the remaining seasoning ingredients. The next step is to combine all the ingredients for the salad. Into a large salad bowl, add grated papaya, carrot, sliced tomato, the remaining peanuts and steamed corn. Pour dressing over the grated the vegetables and toss them in the dressing. Check the salt, spice and sugar levels and adjust to suit your taste.Serve the Thai Spicy Corn & Green Papaya Salad as an appetizer for the parties or as a side dish for the main course along with the Thai Curry and steamed rice. |\n",
      "| TranslatedInstructions | To begin making the Thai Spicy Corn and Green Papaya Salad Recipe, we will first grate carrots and papaya. I personally like to use a Food Processor's Grater attachment to grate the raw green papaya and the carrots. The processor simplifies the process of making the salad. To prepare the dressing for the salad, in a pestle and mortar, add the garlic, grated ginger, chillies and lightly pound them. Add the sugar, lemon juice and soy sauce, pound with the pestle and pound again. Add half of the roasted peanuts and lightly pound along with the remaining seasoning ingredients. The next step is to combine all the ingredients for the salad. Into a large salad bowl, add grated papaya, carrot, sliced tomato, the remaining peanuts and steamed corn. Pour dressing over the grated the vegetables and toss them in the dressing. Check the salt, spice and sugar levels and adjust to suit your taste.Serve the Thai Spicy Corn & Green Papaya Salad as an appetizer for the parties or as a side dish for the main course along with the Thai Curry and steamed rice. |\n",
      "| URL                    | http://www.archanaskitchen.com/thai-spicy-corn-green-papaya-salad-recipe-som-tum-khao-pod                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |\n",
      "| ComplexityLevel        | Hard                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |\n",
      "| MainIngredient         | grated                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |\n",
      "10607\n",
      "|                        | 3134                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |\n",
      "|:-----------------------|:--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
      "| RecipeName             | आलू पोहा रेसिपी- Aloo Poha Recipe                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |\n",
      "| TranslatedRecipeName   | Aloo Poha Recipe                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |\n",
      "| Ingredients            | 1-1/2 कप पोहा,1 or 2 आलू - boiled,1/4 कप हरे मटर - steamed,1/2 छोटा चम्मच राइ,1/2 छोटा चम्मच जीरा,5-6 कढ़ी पत्ता - finely chopped,1 प्याज - finely chopped onion,2 हरी मिर्च - slit lengthwise,1 छोटा चम्मच अदरक - finely grated,1/2 छोटा चम्मच हल्दी पाउडर,1/4 छोटा चम्मच हींग,2 छोटे चम्मच शक्कर,1 निम्बू - juiced,1 बड़ा चम्मच मूंगफली,2 बड़े चम्मच तेल,2 बड़े चम्मच हरा धनिया - finely chopped,3/4 कप अनार - to serve,नमक - salt to taste,1/2 कप स्वीट कॉर्न - steamed,1/2 कप हरे मुंग - अंकुरित                                                                                                                          |\n",
      "| TranslatedIngredients  | 1-1 / 2 cup poha, 1 or 2 potatoes - boiled, 1/2 cup green peas - steamed, 1/2 tsp rye, 1/2 tsp cumin seeds, 5-6 curry leaves - finely chopped, 1 onion - finely chopped onion, 2 green chillies - slit lengthwise, 1 tsp ginger - finely grated, 1/2 tsp turmeric powder, 1/4 tsp asafoetida, 2 tsp sugar, 1 lemon-juiced, 1 tbsp peanuts, 2 Tbsp oil, 2 tbsp coriander - finely chopped, 3/4 cup pomegranate - to serve, salt - salt to taste, 1/2 cup sweet corn - steamed, 1/2 cup green mung - sprouts                                              |\n",
      "| PrepTimeInMins         | 20                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |\n",
      "| CookTimeInMins         | 30                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |\n",
      "| TotalTimeInMins        | 50                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |\n",
      "| Servings               | 4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |\n",
      "| Cuisine                | Indian                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |\n",
      "| Course                 | Indian Breakfast                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |\n",
      "| Diet                   | Vegetarian                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |\n",
      "| Instructions           | आलू पोहा रेसिपी बनाने के लिए सबसे पहले पोहा को ठन्डे पानी के निचे रखें और अच्छी तरह से धो ले. जब पोहा नरम हो जाई तब सारा पानी निकाल ले. ध्यान रखें पानी अच्छी तरह से निकाल ले.अब पोहे को एक बाउल में निकाल ले. इसमें हल्दी पाउडर, नमक, शक्कर, हींग डाले और अलग से रख ले. एक कढ़ाई में तेल गरम करें। इसमें राइ, जीरा डाले और राइ को तड़कने तक पकाए। अब इसमें प्याज, कढ़ी पत्ता, अदरक, हरी मिर्च डाले कर प्याज के नरम होने तक पका ले. अब इसमें उबले हुए आलू डाले और 1 से 2 मिनट तक पका ले. अब पोहा, 1 बड़ा चम्मच पानी डाले और मिला ले. कढ़ाई को ढ़के और 4 से 5 मिनट तक धीमी आंच पर पकने दे. इसके बाद निम्बू का रस, हरे मटर, मूंगफली, हरा धनिया, अनार के दाने डाले और परोसे। आलू पोहा रेसिपी को सुबह के नाश्ते के लिए एक गरम कप मसाला चाय के साथ परोसे। |\n",
      "| TranslatedInstructions | आलू पोहा रेसिपी बनाने के लिए सबसे पहले पोहा को ठन्डे पानी के निचे रखें और अच्छी तरह से धो ले. जब पोहा नरम हो जाई तब सारा पानी निकाल ले. ध्यान रखें पानी अच्छी तरह से निकाल ले.अब पोहे को एक बाउल में निकाल ले. इसमें हल्दी पाउडर, नमक, शक्कर, हींग डाले और अलग से रख ले. एक कढ़ाई में तेल गरम करें। इसमें राइ, जीरा डाले और राइ को तड़कने तक पकाए। अब इसमें प्याज, कढ़ी पत्ता, अदरक, हरी मिर्च डाले कर प्याज के नरम होने तक पका ले. अब इसमें उबले हुए आलू डाले और 1 से 2 मिनट तक पका ले. अब पोहा, 1 बड़ा चम्मच पानी डाले और मिला ले. कढ़ाई को ढ़के और 4 से 5 मिनट तक धीमी आंच पर पकने दे. इसके बाद निम्बू का रस, हरे मटर, मूंगफली, हरा धनिया, अनार के दाने डाले और परोसे। आलू पोहा रेसिपी को सुबह के नाश्ते के लिए एक गरम कप मसाला चाय के साथ परोसे। |\n",
      "| URL                    | http://www.archanaskitchen.com/aloo-poha-recipe-batata-poha-in-hindi                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |\n",
      "| ComplexityLevel        | Hard                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |\n",
      "| MainIngredient         | poha                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |\n",
      "19637\n",
      "|                        | 10134                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |\n",
      "|:-----------------------|:------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
      "| RecipeName             | Dhungare Baingan Recipe                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               |\n",
      "| TranslatedRecipeName   | Dhungare Baingan Recipe                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               |\n",
      "| Ingredients            | 1 Brinjal (Baingan / Eggplant),2 cups Curd (Dahi / Yogurt),1 Green Chilli - chopped,1 teaspoon Cumin powder (Jeera),1/2 teaspoon Kashmiri Red Chilli Powder,1/2 teaspoon Garam masala powder,1 Onion - sliced,Salt - to taste,1 tablespoons Ghee,2 tablespoons Coriander (Dhania) Leaves - chopped                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |\n",
      "| TranslatedIngredients  | 1 Brinjal (Baingan / Eggplant),2 cups Curd (Dahi / Yogurt),1 Green Chilli - chopped,1 teaspoon Cumin powder (Jeera),1/2 teaspoon Kashmiri Red Chilli Powder,1/2 teaspoon Garam masala powder,1 Onion - sliced,Salt - to taste,1 tablespoons Ghee,2 tablespoons Coriander (Dhania) Leaves - chopped                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |\n",
      "| PrepTimeInMins         | 5                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |\n",
      "| CookTimeInMins         | 20                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |\n",
      "| TotalTimeInMins        | 25                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |\n",
      "| Servings               | 4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |\n",
      "| Cuisine                | Lucknowi                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |\n",
      "| Course                 | Side Dish                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |\n",
      "| Diet                   | Vegetarian                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |\n",
      "| Instructions           | To begin making Dhungare Baingan Recipe first we will roast a whole eggplant over an open gas flame till the skin is charred. Turn off the flame and remove the charred baigan onto a plate. Once the eggplant is cooled, peel away the charred skin. Mash the smoked baingan well and put into a pot which has a tight lid. Add in the curd,onions, green chillies, roasted cumin powder, garam masala powder,red chilli powder, salt to taste. Stir well to combine. To give it second smoke using coalKeep a piece of coal over a flame and heat till it turns red hot in colour.Place a small bowl on top of baigan mixture and place the hot burning coal in the small bowl. Drop ghee on the coal and  =once the coal begins to smoke close the lid of the pot quickly. Keep it closed for five minutes to let the flavours of the smoke seep into the baigan. After 5 minutes open the lid and remove the coal bowl. Garnish Dhungare Baingan with coriander leaves and serve.Serve Dhungare Baingan with Aromatic Vegetable Pulao or Garlic Naan and  Nawabi Kofta Curry for your next party. |\n",
      "| TranslatedInstructions | To begin making Dhungare Baingan Recipe first we will roast a whole eggplant over an open gas flame till the skin is charred. Turn off the flame and remove the charred baigan onto a plate. Once the eggplant is cooled, peel away the charred skin. Mash the smoked baingan well and put into a pot which has a tight lid. Add in the curd,onions, green chillies, roasted cumin powder, garam masala powder,red chilli powder, salt to taste. Stir well to combine. To give it second smoke using coalKeep a piece of coal over a flame and heat till it turns red hot in colour.Place a small bowl on top of baigan mixture and place the hot burning coal in the small bowl. Drop ghee on the coal and  =once the coal begins to smoke close the lid of the pot quickly. Keep it closed for five minutes to let the flavours of the smoke seep into the baigan. After 5 minutes open the lid and remove the coal bowl. Garnish Dhungare Baingan with coriander leaves and serve.Serve Dhungare Baingan with Aromatic Vegetable Pulao or Garlic Naan and  Nawabi Kofta Curry for your next party. |\n",
      "| URL                    | http://www.archanaskitchen.com/dhungare-baingan-recipe                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                |\n",
      "| ComplexityLevel        | Medium                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                |\n",
      "| MainIngredient         | Eggplant)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |\n",
      "19349\n",
      "|                        | 7314                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |\n",
      "|:-----------------------|:--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
      "| RecipeName             | Bengali Style Kanch kolar Kofta Curry Recipe (Green Plantain Kofta Curry Recipe)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |\n",
      "| TranslatedRecipeName   | Bengali Style Kanch kolar Kofta Curry Recipe (Green Plantain Kofta Curry Recipe)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |\n",
      "| Ingredients            | 1 Raw Banana,2 Potatoes (Aloo) - boiled,1 teaspoon Turmeric powder (Haldi),2 teaspoon Panch Phoran Masala,2 teaspoon Red Chilli powder,1 Tomato,1 inch Ginger - grated,2 Green Chillies - finely chopped,2 teaspoon Cumin seeds (Jeera),1/2 teaspoon Sugar,1 teaspoon Turmeric powder (Haldi),2 teaspoon Cumin powder (Jeera),1 teaspoon Garam masala powder,1/2 teaspoon Red Chilli powder,2 Bay leaf (tej patta),2 sprig Coriander (Dhania) Leaves - chopped                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |\n",
      "| TranslatedIngredients  | 1 Raw Banana,2 Potatoes (Aloo) - boiled,1 teaspoon Turmeric powder (Haldi),2 teaspoon Panch Phoran Masala,2 teaspoon Red Chilli powder,1 Tomato,1 inch Ginger - grated,2 Green Chillies - finely chopped,2 teaspoon Cumin seeds (Jeera),1/2 teaspoon Sugar,1 teaspoon Turmeric powder (Haldi),2 teaspoon Cumin powder (Jeera),1 teaspoon Garam masala powder,1/2 teaspoon Red Chilli powder,2 Bay leaf (tej patta),2 sprig Coriander (Dhania) Leaves - chopped                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |\n",
      "| PrepTimeInMins         | 10                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |\n",
      "| CookTimeInMins         | 30                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |\n",
      "| TotalTimeInMins        | 40                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |\n",
      "| Servings               | 4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |\n",
      "| Cuisine                | Bengali Recipes                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |\n",
      "| Course                 | Main Course                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |\n",
      "| Diet                   | Vegetarian                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |\n",
      "| Instructions           | We begin making the Bengali Style Kanch kolar Kofta Curry Recipe (Green Plantain Kofta Curry Recipe) by boiling the peeled raw banana and potatoes in a pressure cooker for 4 whistles and release the pressure naturally.In the mean while heat the pan with oil and sauté the tomatoes till it is soft and mushy.  Add salt and sprinkle little sugar to reduce the tanginess. Then let it cool down and grind the tomato into a puree consistency.Once the potatoes and raw bananas are cooked, smash it along with the all the masala powders and make it into a ball. Pan Fry them on the Kuzi Paniyaram Pan till it is brown evenly. Keep it aside.Heat a kadai with oil, add bay leaf and crackle cumin seeds, then add the tomato puree, add in all the spice powders mentioned in the gravy list. Add 1 cup of water and let it boil for about 15 minutes.Once it thickens slightly add in the koftas and sprinkle with chopped coriander seeds. Serve the Bengali Style Kanch kolar Kofta Curry Recipe (Green Plantain Kofta Curry Recipe) with hot Phulkas and steam rice. |\n",
      "| TranslatedInstructions | We begin making the Bengali Style Kanch kolar Kofta Curry Recipe (Green Plantain Kofta Curry Recipe) by boiling the peeled raw banana and potatoes in a pressure cooker for 4 whistles and release the pressure naturally.In the mean while heat the pan with oil and sauté the tomatoes till it is soft and mushy.  Add salt and sprinkle little sugar to reduce the tanginess. Then let it cool down and grind the tomato into a puree consistency.Once the potatoes and raw bananas are cooked, smash it along with the all the masala powders and make it into a ball. Pan Fry them on the Kuzi Paniyaram Pan till it is brown evenly. Keep it aside.Heat a kadai with oil, add bay leaf and crackle cumin seeds, then add the tomato puree, add in all the spice powders mentioned in the gravy list. Add 1 cup of water and let it boil for about 15 minutes.Once it thickens slightly add in the koftas and sprinkle with chopped coriander seeds. Serve the Bengali Style Kanch kolar Kofta Curry Recipe (Green Plantain Kofta Curry Recipe) with hot Phulkas and steam rice. |\n",
      "| URL                    | http://www.archanaskitchen.com/bengali-style-kanch-kolar-kofta-curry-recipe-green-plantain-kofta-curry-recipe                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |\n",
      "| ComplexityLevel        | Hard                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |\n",
      "| MainIngredient         | Banana                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                |\n",
      "25361\n",
      "|                        | 8214                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                |\n",
      "|:-----------------------|:------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
      "| RecipeName             | Creamy Pumpkin Pasta Sauce Recipe                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   |\n",
      "| TranslatedRecipeName   | Creamy Pumpkin Pasta Sauce Recipe                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   |\n",
      "| Ingredients            | 500 grams Kaddu (Parangikai/ Pumpkin) - peeled and diced,4 cloves Garlic - finely chopped,1 Red Bell pepper (Capsicum) - finely chopped,1 tablespoon Extra Virgin Olive Oil,200 ml Milk,1/4 cup Britannia Cream Cheese - flavored like jalepeno or peppers works great,Salt - to taste                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |\n",
      "| TranslatedIngredients  | 500 grams Kaddu (Parangikai/ Pumpkin) - peeled and diced,4 cloves Garlic - finely chopped,1 Red Bell pepper (Capsicum) - finely chopped,1 tablespoon Extra Virgin Olive Oil,200 ml Milk,1/4 cup Britannia Cream Cheese - flavored like jalepeno or peppers works great,Salt - to taste                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |\n",
      "| PrepTimeInMins         | 0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   |\n",
      "| CookTimeInMins         | 30                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |\n",
      "| TotalTimeInMins        | 30                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |\n",
      "| Servings               | 1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   |\n",
      "| Cuisine                | Italian Recipes                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |\n",
      "| Course                 | Vegetarian                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |\n",
      "| Diet                   | Eggetarian                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |\n",
      "| Instructions           | To begin making the Creamy Pumpkin Pasta Sauce Recipe; first get all the ingredients ready and keep it by the side.Heat oil in a wok on medium heat, add in the garlic, red peppers and pumpkin. Sprinkle some salt and stir fry to combine for a couple of minutes. Cover the pan, turn the heat to low and allow the pumpkin and peppers to cook until soft and tender. Do make sure to keep stirring intermittently so the vegetables dont get burnt. You will know the pumpkin is cooked, when you press it down with a fork or a spoon, it will mash itself up.Turn off the heat. Now we are ready to blend all the ingredients together into the blender.Note: If your blender does not allow hot ingredients, then allow the pumpkin to cool before blending it. I use a KitchenAid Diamond Blender and that blends even hot ingredients without splashing all over.If your blender can take in hot inrgedients, then add all of it right away.Add all the ingredients like the cooked pumpkin, peppers, milk and cream cheese into the blender and blend to make a smooth puree. Once blended, check the salt and pepper levels and adjust to suit your taste. The creamy pumpkin puree can now be used as a pasta sauce for lasagna's or even regular pastas.Store the Creamy Pumpkin Sauce in a glass jar or bottle, and refrigerate it for a maximum of 3 to 4 days and use it as and when required to make fresh pasta. |\n",
      "| TranslatedInstructions | To begin making the Creamy Pumpkin Pasta Sauce Recipe; first get all the ingredients ready and keep it by the side.Heat oil in a wok on medium heat, add in the garlic, red peppers and pumpkin. Sprinkle some salt and stir fry to combine for a couple of minutes. Cover the pan, turn the heat to low and allow the pumpkin and peppers to cook until soft and tender. Do make sure to keep stirring intermittently so the vegetables dont get burnt. You will know the pumpkin is cooked, when you press it down with a fork or a spoon, it will mash itself up.Turn off the heat. Now we are ready to blend all the ingredients together into the blender.Note: If your blender does not allow hot ingredients, then allow the pumpkin to cool before blending it. I use a KitchenAid Diamond Blender and that blends even hot ingredients without splashing all over.If your blender can take in hot inrgedients, then add all of it right away.Add all the ingredients like the cooked pumpkin, peppers, milk and cream cheese into the blender and blend to make a smooth puree. Once blended, check the salt and pepper levels and adjust to suit your taste. The creamy pumpkin puree can now be used as a pasta sauce for lasagna's or even regular pastas.Store the Creamy Pumpkin Sauce in a glass jar or bottle, and refrigerate it for a maximum of 3 to 4 days and use it as and when required to make fresh pasta. |\n",
      "| URL                    | https://www.archanaskitchen.com/creamy-pumpkin-pasta-sauce-recipe                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   |\n",
      "| ComplexityLevel        | Medium                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |\n",
      "| MainIngredient         | diced                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               |\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = vector_store.similarity_search(\n",
    "    'Andhra Dish with Onion and No Ginger', k=5)\n",
    "for result in results:\n",
    "    print(len(result.page_content))\n",
    "    print(result.page_content)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/GenAIEngineering-Cohort1/.venv/lib/python3.12/site-packages/langchain_qdrant/vectorstores.py:180: UserWarning: Local mode is not recommended for collections with more than 20,000 points. Current collection contains 20032 points. Consider using Qdrant in Docker or Qdrant Cloud for better performance with large datasets.\n",
      "  self.client.upsert(\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=100,\n",
    "    length_function=len\n",
    ")\n",
    "\n",
    "docs = text_splitter.create_documents(\n",
    "    data,\n",
    ")\n",
    "\n",
    "\n",
    "vector_store = Qdrant.from_documents(\n",
    "    docs,\n",
    "    model_768,\n",
    "    collection_name=\"indian-food-chunked\",\n",
    "    location=':memory:',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/datasets/razanaqvi14/real-and-fake-news\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.concat(\n",
    "    [\n",
    "        pd.read_csv('true.csv'),\n",
    "        pd.read_csv('fake.csv'),\n",
    "    ]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
