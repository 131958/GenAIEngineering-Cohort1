{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Relevant imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Vishnu\\Files\\vEnV\\RAG_Str\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import io\n",
    "from dotenv import load_dotenv\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from groq import Groq\n",
    "from sqlalchemy import create_engine, text, Result\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Embedder**  \n",
    "Embedder model is used from sentence transformer  \n",
    "This is used for making semantic search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load embedder model\n",
    "# model = SentenceTransformer('all-mpnet-base-v2')\n",
    "model = SentenceTransformer('paraphrase-multilingual-mpnet-base-v2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Similarity Search**  \n",
    "This function makes the semantic similarity search of a string  \n",
    "It searches the strings that are closely related to search string by meanining  \n",
    "The reference strings re-ordered based on the similarity  \n",
    "If there is a distance threshold provided, only the ones relevant are provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def semantic_similarity_rank(\n",
    "    search_string: str,\n",
    "    sentences: list[str],\n",
    "    threshold: float = 0.0\n",
    ") -> tuple[list[str], list[int]]:\n",
    "    \"\"\"\n",
    "    Ranks sentences based on semantic similarity to the search_string.\n",
    "\n",
    "    Args:\n",
    "        search_string (str): The input query.\n",
    "        sentences (list[str]): List of sentences to compare.\n",
    "        threshold (float): Similarity threshold (0 means no threshold).\n",
    "\n",
    "    Returns:\n",
    "        tuple: (reordered_sentences, original_indexes)\n",
    "    \"\"\"\n",
    "\n",
    "    # Encode search string and sentence list\n",
    "    search_embedding = model.encode(search_string, convert_to_tensor=True)\n",
    "    sentence_embeddings = model.encode(sentences, convert_to_tensor=True)\n",
    "\n",
    "    # Compute cosine similarity score\n",
    "    cosine_scores = util.cos_sim(search_embedding, sentence_embeddings)[0]\n",
    "\n",
    "    # Pair sentences with scores and original indices\n",
    "    indexed_scores = [\n",
    "        (i, s, float(score)) for i, (s, score) in enumerate(zip(sentences, cosine_scores))\n",
    "        if threshold == 0.0 or float(score) >= threshold\n",
    "    ]\n",
    "\n",
    "    # Sort by score descending\n",
    "    indexed_scores.sort(key=lambda x: x[2], reverse=True)\n",
    "\n",
    "    # Extract reordered sentences and original indices\n",
    "    reordered_sentences = [s for _, s, _ in indexed_scores]\n",
    "    original_indexes = [i for i, _, _ in indexed_scores]\n",
    "\n",
    "    # Output the reordered senteces and the re-ordered indices in original set\n",
    "    return reordered_sentences, original_indexes\n",
    "    \n",
    "    # # Additional output\n",
    "    # scores = [sc[2] for sc in indexed_scores]\n",
    "    # return reordered_sentences, original_indexes, scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read Data File**  \n",
    "Data File with call record summary read into data frame and the summary column segregated as a list of string  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV and consider the relevant column in a list\n",
    "Data = pd.read_csv ('call_records.csv')\n",
    "Summary = Data['Call Summary'].astype (str).tolist ()\n",
    "# Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Semantic Search**  \n",
    "For different criteria in the call summary, semantic search is made to capture the indices  \n",
    "Diff threshold values depending on the criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CB_Criteria = \"follow up request\"\n",
    "Shortlist, CB_Order = semantic_similarity_rank (CB_Criteria, Summary, 0.4)\n",
    "print (CB_Order)\n",
    "\n",
    "CL_Criteria = \"clarification sought\"\n",
    "Shortlist, CL_Order = semantic_similarity_rank (CL_Criteria, Summary, 0.3)\n",
    "print (CL_Order)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Update in CSV**  \n",
    "Respective records are marked for the criteria match  \n",
    "This can further be used in the process as structured data file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data.loc [CB_Order, [CB_Criteria]] = 'Yes'\n",
    "Data.loc [CL_Order, [CL_Criteria]] = 'Yes'\n",
    "Data.to_csv ('call_record_updated.csv', index=False)\n",
    "Data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAG_Str",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
